{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11494853,
          "sourceType": "datasetVersion",
          "datasetId": 7205812
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Step:1**"
      ],
      "metadata": {
        "id": "UNwCUzN1nRYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path='/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv'\n",
        "valid_data_path='/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv'\n",
        "test_data_path='/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv'"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T01:37:46.761921Z",
          "iopub.execute_input": "2025-05-15T01:37:46.762194Z",
          "iopub.status.idle": "2025-05-15T01:37:46.768545Z",
          "shell.execute_reply.started": "2025-05-15T01:37:46.762169Z",
          "shell.execute_reply": "2025-05-15T01:37:46.768003Z"
        },
        "id": "mMaYFJYAy9OT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step:2**"
      ],
      "metadata": {
        "id": "2-c6hzmanVDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "def load_and_prepare_data(path, batch_size=32):\n",
        "    df = pd.read_csv(path, delimiter=\"\\t\", header=None)\n",
        "    df.columns = ['target_word', 'input_word', 'dummy']\n",
        "    df = df.drop(columns=['dummy'])\n",
        "    df = df.dropna()\n",
        "    df = df.reset_index(drop=True)\n",
        "    df['input_word'] = df['input_word'].astype(str)\n",
        "    df['target_word'] = df['target_word'].astype(str)\n",
        "\n",
        "    max_input_len = max(len(word) for word in df['input_word'])\n",
        "    max_target_len = max(len(word) for word in df['target_word'])\n",
        "\n",
        "    input_letter_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "    target_letter_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "    letter_idx = 3\n",
        "\n",
        "    for letter in sorted(set(''.join(df['input_word']))):\n",
        "        input_letter_vocab[letter] = letter_idx\n",
        "        letter_idx += 1\n",
        "\n",
        "    letter_idx = 3\n",
        "    for letter in sorted(set(''.join(df['target_word']))):\n",
        "        if letter not in target_letter_vocab:\n",
        "            target_letter_vocab[letter] = letter_idx\n",
        "            letter_idx += 1\n",
        "\n",
        "    def encode_input_letters(word):\n",
        "        token_ids = [input_letter_vocab[char] for char in word if char in input_letter_vocab]\n",
        "        padded = token_ids[:max_input_len] + [input_letter_vocab['<pad>']] * (max_input_len - len(token_ids))\n",
        "        return padded\n",
        "\n",
        "    def encode_target_letters(word):\n",
        "        token_ids = [target_letter_vocab[char] for char in word if char in target_letter_vocab]\n",
        "        padded = [target_letter_vocab['<pad>']] + token_ids[:max_target_len] + [target_letter_vocab['<pad>']] * (max_target_len - len(token_ids))\n",
        "        return padded\n",
        "\n",
        "    input_tensors = [torch.tensor(encode_input_letters(word)) for word in df['input_word']]\n",
        "    target_tensors = [torch.tensor(encode_target_letters(word)) for word in df['target_word']]\n",
        "\n",
        "    input_tensors = torch.stack(input_tensors)\n",
        "    target_tensors = torch.stack(target_tensors)\n",
        "\n",
        "    dataset = TensorDataset(input_tensors, target_tensors)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return dataset, data_loader, input_letter_vocab, target_letter_vocab, max_input_len, max_target_len\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T01:37:50.393549Z",
          "iopub.execute_input": "2025-05-15T01:37:50.394259Z",
          "iopub.status.idle": "2025-05-15T01:37:59.676195Z",
          "shell.execute_reply.started": "2025-05-15T01:37:50.394235Z",
          "shell.execute_reply": "2025-05-15T01:37:59.675619Z"
        },
        "id": "-_7_q_tZy9OU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:3**"
      ],
      "metadata": {
        "id": "zP7VlCMZnZGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset,train_loader_ben,train_input_vocab,train_target_vocab,max_train_input_len,max_train_target_len =load_and_prepare_data(train_data_path,batch_size = 64)\n",
        "print(train_input_vocab,train_target_vocab,max_train_input_len,max_train_target_len)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T01:38:03.305876Z",
          "iopub.execute_input": "2025-05-15T01:38:03.306514Z",
          "iopub.status.idle": "2025-05-15T01:38:05.987990Z",
          "shell.execute_reply.started": "2025-05-15T01:38:03.306490Z",
          "shell.execute_reply": "2025-05-15T01:38:05.987268Z"
        },
        "id": "9Qr6o2IPy9OV",
        "outputId": "386cc82f-a8c9-4e0c-b647-060e6e6e4e16"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{'<pad>': 0, '<sos>': 1, '<eos>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28} {'<pad>': 0, '<sos>': 1, '<eos>': 2, 'ঁ': 3, 'ং': 4, 'ঃ': 5, 'অ': 6, 'আ': 7, 'ই': 8, 'ঈ': 9, 'উ': 10, 'ঊ': 11, 'ঋ': 12, 'এ': 13, 'ঐ': 14, 'ও': 15, 'ঔ': 16, 'ক': 17, 'খ': 18, 'গ': 19, 'ঘ': 20, 'ঙ': 21, 'চ': 22, 'ছ': 23, 'জ': 24, 'ঝ': 25, 'ঞ': 26, 'ট': 27, 'ঠ': 28, 'ড': 29, 'ঢ': 30, 'ণ': 31, 'ত': 32, 'থ': 33, 'দ': 34, 'ধ': 35, 'ন': 36, 'প': 37, 'ফ': 38, 'ব': 39, 'ভ': 40, 'ম': 41, 'য': 42, 'র': 43, 'ল': 44, 'শ': 45, 'ষ': 46, 'স': 47, 'হ': 48, '়': 49, 'া': 50, 'ি': 51, 'ী': 52, 'ু': 53, 'ূ': 54, 'ৃ': 55, 'ে': 56, 'ৈ': 57, 'ো': 58, 'ৌ': 59, '্': 60, 'ৎ': 61, '২': 62} 22 22\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:4**"
      ],
      "metadata": {
        "id": "Vy2UdNC9ncYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def load_and_prepare_test_valid_data(path, batch_size=32,\n",
        "                          input_letter_vocab=None,\n",
        "                          target_letter_vocab=None,\n",
        "                          max_input_len=None,\n",
        "                          max_target_len=None):\n",
        "    df = pd.read_csv(path, delimiter=\"\\t\", header=None)\n",
        "    df.columns = ['target_word', 'input_word', 'dummy']\n",
        "    df = df.drop(columns=['dummy'])\n",
        "    df = df.dropna()\n",
        "    df = df.reset_index(drop=True)\n",
        "    df['input_word'] = df['input_word'].astype(str)\n",
        "    df['target_word'] = df['target_word'].astype(str)\n",
        "    if input_letter_vocab is None:\n",
        "        input_letter_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "        letter_idx = 3\n",
        "        for letter in sorted(set(''.join(df['input_word']))):\n",
        "            input_letter_vocab[letter] = letter_idx\n",
        "            letter_idx += 1\n",
        "    if target_letter_vocab is None:\n",
        "        target_letter_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "        letter_idx = 3\n",
        "        for letter in sorted(set(''.join(df['target_word']))):\n",
        "            if letter not in target_letter_vocab:\n",
        "                target_letter_vocab[letter] = letter_idx\n",
        "                letter_idx += 1\n",
        "    if max_input_len is None:\n",
        "        max_input_len = max(len(word) for word in df['input_word'])\n",
        "    if max_target_len is None:\n",
        "        max_target_len = max(len(word) for word in df['target_word'])\n",
        "    def encode_input_letters(word):\n",
        "        token_ids = [input_letter_vocab[char] for char in word if char in input_letter_vocab]\n",
        "        padded = token_ids[:max_input_len] + [input_letter_vocab['<pad>']] * (max_input_len - len(token_ids))\n",
        "        return padded\n",
        "\n",
        "    def encode_target_letters(word):\n",
        "        token_ids = [target_letter_vocab[char] for char in word if char in target_letter_vocab]\n",
        "        padded = [target_letter_vocab['<sos>']] + token_ids[:max_target_len] + [target_letter_vocab['<eos>']]\n",
        "        padded += [target_letter_vocab['<pad>']] * (max_target_len + 2 - len(padded))  # +2 for <sos> and <eos>\n",
        "        return padded\n",
        "    input_tensors = [torch.tensor(encode_input_letters(word)) for word in df['input_word']]\n",
        "    target_tensors = [torch.tensor(encode_target_letters(word)) for word in df['target_word']]\n",
        "    input_tensors = torch.stack(input_tensors)\n",
        "    target_tensors = torch.stack(target_tensors)\n",
        "    dataset = TensorDataset(input_tensors, target_tensors)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "    return dataset, data_loader, input_letter_vocab, target_letter_vocab, max_input_len, max_target_len"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T01:38:08.336409Z",
          "iopub.execute_input": "2025-05-15T01:38:08.337172Z",
          "iopub.status.idle": "2025-05-15T01:38:08.346937Z",
          "shell.execute_reply.started": "2025-05-15T01:38:08.337142Z",
          "shell.execute_reply": "2025-05-15T01:38:08.346237Z"
        },
        "id": "PULOy95Jy9OV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:5**"
      ],
      "metadata": {
        "id": "74Grib2pngD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset, val_data_loader, val_input_letter_vocab, val_target_letter_vocab,val_max_input_len, val_max_target_len=load_and_prepare_test_valid_data(valid_data_path,64,train_input_vocab,train_target_vocab,max_train_input_len,max_train_target_len)\n",
        "test_dataset, test_data_loader, test_input_letter_vocab, test_target_letter_vocab, test_max_input_len, test_max_target_len=load_and_prepare_test_valid_data(test_data_path,64,train_input_vocab,train_target_vocab,max_train_input_len,max_train_target_len)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T01:38:11.059077Z",
          "iopub.execute_input": "2025-05-15T01:38:11.059348Z",
          "iopub.status.idle": "2025-05-15T01:38:11.574413Z",
          "shell.execute_reply.started": "2025-05-15T01:38:11.059330Z",
          "shell.execute_reply": "2025-05-15T01:38:11.573842Z"
        },
        "id": "wa09O-JRy9OW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:6**"
      ],
      "metadata": {
        "id": "PVjhdT4Jnngd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, embed_size, encoder_layers=1, drop_prob=0.5, cell_type='gru', bidirectional=False):\n",
        "        super(TextEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, embed_size)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.cell_type = cell_type\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        rnn_cls = {'lstm': nn.LSTM, 'gru': nn.GRU, 'rnn': nn.RNN}[cell_type]\n",
        "        self.rnn = rnn_cls(embed_size, hidden_size, encoder_layers,\n",
        "                           dropout=drop_prob, bidirectional=bidirectional, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        return outputs, hidden\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, enc_hidden_size, dec_hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.attn = nn.Linear(enc_hidden_size + dec_hidden_size, dec_hidden_size)\n",
        "        self.v = nn.Parameter(torch.rand(dec_hidden_size))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        batch_size, src_len, _ = encoder_outputs.size()\n",
        "\n",
        "        if len(hidden.shape) == 2:\n",
        "            hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        else:\n",
        "            hidden = hidden[-1].unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
        "        attention = torch.bmm(v, energy.transpose(1, 2)).squeeze(1)\n",
        "        return torch.softmax(attention, dim=1)\n",
        "\n",
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, hidden_size, embed_size, output_size, decoder_layers=1, drop_prob=0.5, cell_type='gru', enc_hidden_size=None):\n",
        "        super(AttnDecoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, embed_size)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.attention = BahdanauAttention(enc_hidden_size, hidden_size)\n",
        "\n",
        "        rnn_cls = {'lstm': nn.LSTM, 'gru': nn.GRU, 'rnn': nn.RNN}[cell_type]\n",
        "        self.rnn = rnn_cls(embed_size + enc_hidden_size, hidden_size, decoder_layers,\n",
        "                           dropout=drop_prob, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, encoder_outputs):\n",
        "        x = x.unsqueeze(1)\n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        attn_weights = self.attention(hidden[-1], encoder_outputs)\n",
        "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
        "        rnn_input = torch.cat((embedded, context), dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "        output = self.fc(output.squeeze(1))\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "class Seq2SeqModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size, embed_size, beam_width,\n",
        "                 encoder_layers=1, decoder_layers=1, drop_prob=0.3, cell_type='gru', bidirectional=True):\n",
        "        super(Seq2SeqModel, self).__init__()\n",
        "        self.encoder = TextEncoder(input_size, hidden_size, embed_size,\n",
        "                                   encoder_layers, drop_prob, cell_type, bidirectional)\n",
        "\n",
        "        self.bidirectional = bidirectional\n",
        "        self.beam_width = beam_width\n",
        "        enc_hidden_size = 2 * hidden_size if bidirectional else hidden_size\n",
        "\n",
        "        self.decoder = AttnDecoder(hidden_size, embed_size, output_size,\n",
        "                                   decoder_layers, drop_prob, cell_type,\n",
        "                                   enc_hidden_size=enc_hidden_size)\n",
        "\n",
        "        self.cell_type = cell_type\n",
        "        self.encoder_layers = encoder_layers\n",
        "        self.decoder_layers = decoder_layers\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        batch_size = source.size(0)\n",
        "        target_len = target.size(1)\n",
        "        output_vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, target_len, output_vocab_size).to(source.device)\n",
        "        all_attention_weights = []\n",
        "\n",
        "        encoder_outputs, encoder_hidden = self.encoder(source)\n",
        "        decoder_hidden = self._init_decoder_hidden(encoder_hidden)\n",
        "        decoder_input = target[:, 0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            outputs[:, t] = decoder_output\n",
        "            all_attention_weights.append(attn_weights)\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            decoder_input = target[:, t] if teacher_force else decoder_output.argmax(1)\n",
        "\n",
        "        all_attention_weights = torch.stack(all_attention_weights, dim=1)\n",
        "        return outputs, all_attention_weights\n",
        "\n",
        "    def _init_decoder_hidden(self, encoder_hidden):\n",
        "        decoder_layers = self.decoder.rnn.num_layers\n",
        "        if self.cell_type == 'lstm':\n",
        "            h, c = encoder_hidden\n",
        "            if h.shape[0] > 1 and self.bidirectional:\n",
        "                h = self._merge_bidirectional(h)\n",
        "                c = self._merge_bidirectional(c)\n",
        "            h = self._pad_or_trim(h, decoder_layers)\n",
        "            c = self._pad_or_trim(c, decoder_layers)\n",
        "            return (h, c)\n",
        "        else:\n",
        "            h = encoder_hidden\n",
        "            if h.shape[0] > 1 and self.bidirectional:\n",
        "                h = self._merge_bidirectional(h)\n",
        "            h = self._pad_or_trim(h, decoder_layers)\n",
        "            return h\n",
        "\n",
        "    def _merge_bidirectional(self, hidden):\n",
        "        return hidden.view(self.encoder.rnn.num_layers, 2, hidden.size(1), hidden.size(2)).sum(1)\n",
        "\n",
        "    def _pad_or_trim(self, hidden, target_layers):\n",
        "        if hidden.shape[0] < target_layers:\n",
        "            pad = torch.zeros(target_layers - hidden.shape[0], *hidden.shape[1:], device=hidden.device)\n",
        "            return torch.cat([hidden, pad], dim=0)\n",
        "        return hidden[:target_layers]\n",
        "\n",
        "    def beam_search_decode(self, source, sos_idx, eos_idx, max_len=50):\n",
        "        device = source.device\n",
        "        batch_size = source.size(0)\n",
        "        assert batch_size == 1, \"Beam search decoding supports batch size 1 for simplicity.\"\n",
        "\n",
        "        encoder_outputs, encoder_hidden = self.encoder(source)\n",
        "        decoder_hidden = self._init_decoder_hidden(encoder_hidden)\n",
        "\n",
        "        beams = [(0.0, [sos_idx], decoder_hidden, [])]\n",
        "        completed_sequences = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            new_beams = []\n",
        "            for log_prob, seq, hidden, attns in beams:\n",
        "                decoder_input = torch.tensor([[seq[-1]]], device=device)\n",
        "                with torch.no_grad():\n",
        "                    decoder_output, hidden, attn_weights = self.decoder(decoder_input, hidden, encoder_outputs)\n",
        "                    probs = F.log_softmax(decoder_output, dim=1)\n",
        "                    topk_probs, topk_indices = probs.topk(self.beam_width)\n",
        "\n",
        "                for k in range(self.beam_width):\n",
        "                    next_token = topk_indices[0, k].item()\n",
        "                    next_log_prob = log_prob + topk_probs[0, k].item()\n",
        "                    new_seq = seq + [next_token]\n",
        "                    new_attns = attns + [attn_weights]\n",
        "\n",
        "                    if next_token == eos_idx:\n",
        "                        completed_sequences.append((next_log_prob, new_seq, new_attns))\n",
        "                    else:\n",
        "                        new_beams.append((next_log_prob, new_seq, hidden, new_attns))\n",
        "\n",
        "            beams = sorted(new_beams, key=lambda x: x[0], reverse=True)[:self.beam_width]\n",
        "\n",
        "            if len(completed_sequences) >= self.beam_width:\n",
        "                break\n",
        "\n",
        "        if not completed_sequences:\n",
        "            completed_sequences = [(log_prob, seq, attns) for log_prob, seq, _, attns in beams]\n",
        "\n",
        "        completed_sequences = sorted(completed_sequences, key=lambda x: x[0], reverse=True)\n",
        "        best_log_prob, best_seq, best_attns = completed_sequences[0]\n",
        "        return best_seq, best_attns\n",
        "\n",
        "#Traiining function\n",
        "def train_model(model, data_loader, loss_function, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for input_data, target_data in data_loader:\n",
        "        input_data = input_data.to(device)\n",
        "        target_data = target_data.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions, _ = model(input_data, target_data)\n",
        "        output_size = predictions.shape[-1]\n",
        "        predictions = predictions.view(-1, output_size)\n",
        "        target_data = target_data.view(-1)\n",
        "\n",
        "        loss = loss_function(predictions, target_data)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return model, total_loss / len(data_loader)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, data_loader, loss_function, device, pad_token_id=0):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_tokens = 0\n",
        "    correct_tokens = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_data, target_data in data_loader:\n",
        "            input_data = input_data.to(device)\n",
        "            target_data = target_data.to(device)\n",
        "\n",
        "            predictions, _ = model(input_data, target_data, teacher_forcing_ratio=0.0)\n",
        "            output_size = predictions.shape[-1]\n",
        "            loss = loss_function(predictions.view(-1, output_size), target_data.view(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            predicted_tokens = predictions.argmax(dim=-1)\n",
        "            mask = target_data != pad_token_id\n",
        "            correct = (predicted_tokens == target_data) & mask\n",
        "            correct_tokens += correct.sum().item()\n",
        "            total_tokens += mask.sum().item()\n",
        "\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    accuracy = correct_tokens / total_tokens if total_tokens > 0 else 0.0\n",
        "    return average_loss, accuracy * 100\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 29\n",
        "output_size = 63\n",
        "embed_size = 128\n",
        "hidden_size = 128\n",
        "encoder_layers = 3\n",
        "decoder_layers = 2\n",
        "beam_width = 3\n",
        "cell_type = 'lstm'\n",
        "batch_size = 64\n",
        "num_epochs = 20\n",
        "drop_prob = 0.2\n",
        "learning_rate = 0.001\n",
        "bidirectional = True\n",
        "\n",
        "# Model, criterion, optimizer\n",
        "model = Seq2SeqModel(input_size, output_size, hidden_size, embed_size,\n",
        "                     beam_width, encoder_layers, decoder_layers,\n",
        "                     drop_prob, cell_type, bidirectional)\n",
        "\n",
        "print(model)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T01:38:13.654041Z",
          "iopub.execute_input": "2025-05-15T01:38:13.654354Z",
          "iopub.status.idle": "2025-05-15T01:38:19.513073Z",
          "shell.execute_reply.started": "2025-05-15T01:38:13.654334Z",
          "shell.execute_reply": "2025-05-15T01:38:19.512347Z"
        },
        "id": "lqwsDcUoy9OW",
        "outputId": "7539fccb-468e-451d-c41d-bfc2c52262d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 128)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(128, 128, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): AttnDecoder(\n    (embedding): Embedding(63, 128)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (attention): BahdanauAttention(\n      (attn): Linear(in_features=384, out_features=128, bias=True)\n    )\n    (rnn): LSTM(384, 128, num_layers=2, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=128, out_features=63, bias=True)\n  )\n)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:7**"
      ],
      "metadata": {
        "id": "NcamH-kzn019"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import numpy as np\n",
        "from types import SimpleNamespace\n",
        "import random"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T02:05:32.984308Z",
          "iopub.execute_input": "2025-05-15T02:05:32.984568Z",
          "iopub.status.idle": "2025-05-15T02:05:36.410767Z",
          "shell.execute_reply.started": "2025-05-15T02:05:32.984547Z",
          "shell.execute_reply": "2025-05-15T02:05:36.410253Z"
        },
        "id": "FROyVuVWy9OW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:8**"
      ],
      "metadata": {
        "id": "9Oy682z4n6GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "api_key = getpass.getpass(\"Enter your W&B API Key: \")  # Hidden input\n",
        "wandb.login(key=api_key)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T02:05:38.699333Z",
          "iopub.execute_input": "2025-05-15T02:05:38.700012Z",
          "iopub.status.idle": "2025-05-15T02:05:51.453068Z",
          "shell.execute_reply.started": "2025-05-15T02:05:38.699987Z",
          "shell.execute_reply": "2025-05-15T02:05:51.452504Z"
        },
        "id": "h8O4SF7py9OW",
        "outputId": "90ee5cf2-832e-43d5-c843-dfc505bc07a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Enter your W&B API Key:  ········\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma24m022\u001b[0m (\u001b[33mma24m022-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
          "output_type": "stream"
        },
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:9**"
      ],
      "metadata": {
        "id": "1nAxoUwvn9QO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'embedding_size': {\n",
        "            'values': [256, 192, 128, 64, 32]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.0,0.1,0.2,0.3,0.4,0.5]\n",
        "        },\n",
        "        'encoder_layers': {\n",
        "            'values': [1,2,3]\n",
        "        },\n",
        "        'decoder_layers': {\n",
        "            'values': [1,2,3]\n",
        "        },\n",
        "        'hidden_layer_size': {\n",
        "            'values': [512, 256, 192, 128, 64]\n",
        "        },\n",
        "        'cell_type': {\n",
        "            'values': ['lstm', 'rnn', 'gru']\n",
        "        },\n",
        "        'bidirectional': {\n",
        "            'values': [True, False]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [128, 64, 32, 16]\n",
        "        },\n",
        "        'num_epochs': {\n",
        "            'values': [5]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [0.0001, 0.001, 0.005, 0.01]\n",
        "        },\n",
        "         'beam_width': {\n",
        "            'values': [10, 5, 3, 2, 1]  # 1 = greedy decoding\n",
        "        }\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='DL_Translation_attention')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T02:05:54.072755Z",
          "iopub.execute_input": "2025-05-15T02:05:54.073501Z",
          "iopub.status.idle": "2025-05-15T02:05:54.302189Z",
          "shell.execute_reply.started": "2025-05-15T02:05:54.073476Z",
          "shell.execute_reply": "2025-05-15T02:05:54.301588Z"
        },
        "id": "FTWUVE9Vy9OW",
        "outputId": "a58fbc7a-ef96-4471-8d81-f5046db73bcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Create sweep with ID: 7zxwuoi9\nSweep URL: https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:10**"
      ],
      "metadata": {
        "id": "E0qcwcleoBSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    with wandb.init() as run:\n",
        "        run_name=\"ct-\"+str(wandb.config.cell_type)+\"_el-\"+str(wandb.config.encoder_layers)+\"_dl-\"+str(wandb.config.decoder_layers)+\"_drop-\"+str(wandb.config.dropout)+\"_es-\"+str(wandb.config.embedding_size)+\"_hs-\"+str(wandb.config.hidden_layer_size)+\"_bs-\"+str(wandb.config.batch_size)+\"_ep-\"+str(wandb.config.num_epochs)+\"lr\"+str(wandb.config.learning_rate)\n",
        "        wandb.run.name=run_name\n",
        "\n",
        "        model = Seq2SeqModel(input_size=29, output_size=63, hidden_size=wandb.config.hidden_layer_size,embed_size=wandb.config.embedding_size,beam_width=wandb.config.beam_width,encoder_layers=wandb.config.encoder_layers,\n",
        "                        decoder_layers=wandb.config.decoder_layers,drop_prob=wandb.config.dropout, cell_type=wandb.config.cell_type, bidirectional=wandb.config.bidirectional)\n",
        "        print(model)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "        custom_dataset1,train_loader_ben,a,b,_,_ = load_and_prepare_data(train_data_path,batch_size = wandb.config.batch_size)\n",
        "        custom_dataset,val_loader_ben,_,_,_,_ =load_and_prepare_data(valid_data_path,batch_size = wandb.config.batch_size)\n",
        "        for epoch in range(wandb.config.num_epochs):\n",
        "            trained_model, train_loss = train_model(model, train_loader_ben, criterion, optimizer, device)\n",
        "            val_loss, val_accuracy = evaluate_model(trained_model,val_data_loader, criterion, device)\n",
        "            model = trained_model\n",
        "            wandb.log({'Epoch': epoch, 'train_loss': train_loss , ' val_loss': val_loss, 'val_accuracy':val_accuracy})\n",
        "            print(f'Epoch {epoch+1}/{wandb.config.num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "wandb.agent(sweep_id, function= main,count=15)\n",
        "# wandb.finish()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T02:05:58.280264Z",
          "iopub.execute_input": "2025-05-15T02:05:58.280813Z",
          "iopub.status.idle": "2025-05-15T03:10:49.217433Z",
          "shell.execute_reply.started": "2025-05-15T02:05:58.280793Z",
          "shell.execute_reply": "2025-05-15T03:10:49.216552Z"
        },
        "id": "-XUIQc9Py9OX",
        "outputId": "4849cebc-fa38-4232-e1c6-887e2736fc2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qgpb1h6k with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 192\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250515_020604-qgpb1h6k</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/qgpb1h6k' target=\"_blank\">vocal-sweep-1</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/qgpb1h6k' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/qgpb1h6k</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 192)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): RNN(192, 64, num_layers=2, batch_first=True, dropout=0.3)\n  )\n  (decoder): AttnDecoder(\n    (embedding): Embedding(63, 192)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (attention): BahdanauAttention(\n      (attn): Linear(in_features=128, out_features=64, bias=True)\n    )\n    (rnn): RNN(256, 64, num_layers=3, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=64, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.7995, Val Loss: 1.5928, Val Accuracy: 4.2100\nEpoch 2/5, Train Loss: 1.3800, Val Loss: 1.5987, Val Accuracy: 7.8523\nEpoch 3/5, Train Loss: 1.3103, Val Loss: 1.5592, Val Accuracy: 8.7525\nEpoch 4/5, Train Loss: 1.2808, Val Loss: 1.5503, Val Accuracy: 9.6661\nEpoch 5/5, Train Loss: 1.2631, Val Loss: 1.5834, Val Accuracy: 9.7935\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▇█▂▁▆</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>1.58338</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>1.26307</td></tr><tr><td>val_accuracy</td><td>9.7935</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-rnn_el-2_dl-3_drop-0.3_es-192_hs-64_bs-128_ep-5lr0.0001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/qgpb1h6k' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/qgpb1h6k</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250515_020604-qgpb1h6k/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hjf4xxsu with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250515_020955-hjf4xxsu</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/hjf4xxsu' target=\"_blank\">rich-sweep-2</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/hjf4xxsu' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/hjf4xxsu</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 256)\n    (dropout): Dropout(p=0, inplace=False)\n    (rnn): GRU(256, 128, num_layers=3, batch_first=True)\n  )\n  (decoder): AttnDecoder(\n    (embedding): Embedding(63, 256)\n    (dropout): Dropout(p=0, inplace=False)\n    (attention): BahdanauAttention(\n      (attn): Linear(in_features=256, out_features=128, bias=True)\n    )\n    (rnn): GRU(384, 128, batch_first=True)\n    (fc): Linear(in_features=128, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.1847, Val Loss: 1.6976, Val Accuracy: 9.8481\nEpoch 2/5, Train Loss: 1.0257, Val Loss: 1.6666, Val Accuracy: 12.8849\nEpoch 3/5, Train Loss: 0.9196, Val Loss: 1.6691, Val Accuracy: 17.1423\nEpoch 4/5, Train Loss: 0.8221, Val Loss: 1.5738, Val Accuracy: 23.3263\nEpoch 5/5, Train Loss: 0.7263, Val Loss: 1.5036, Val Accuracy: 30.4081\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>█▇▇▄▁</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▆▄▂▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>1.50355</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.72633</td></tr><tr><td>val_accuracy</td><td>30.40814</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-gru_el-3_dl-1_drop-0_es-256_hs-128_bs-64_ep-5lr0.001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/hjf4xxsu' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/hjf4xxsu</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250515_020955-hjf4xxsu/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 59zq5e28 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250515_021613-59zq5e28</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/59zq5e28' target=\"_blank\">super-sweep-3</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/59zq5e28' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/59zq5e28</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(256, 512, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): AttnDecoder(\n    (embedding): Embedding(63, 256)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (attention): BahdanauAttention(\n      (attn): Linear(in_features=1536, out_features=512, bias=True)\n    )\n    (rnn): LSTM(1280, 512, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=512, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.1066, Val Loss: 1.7676, Val Accuracy: 10.8296\nEpoch 2/5, Train Loss: 0.9089, Val Loss: 1.8390, Val Accuracy: 14.9281\nEpoch 3/5, Train Loss: 0.7108, Val Loss: 1.7446, Val Accuracy: 22.6008\nEpoch 4/5, Train Loss: 0.5650, Val Loss: 1.7866, Val Accuracy: 25.9009\nEpoch 5/5, Train Loss: 0.4781, Val Loss: 1.8113, Val Accuracy: 27.9573\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▃█▁▄▆</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▆▄▂▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>1.81132</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.47808</td></tr><tr><td>val_accuracy</td><td>27.95734</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-lstm_el-3_dl-3_drop-0.2_es-256_hs-512_bs-16_ep-5lr0.0001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/59zq5e28' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/59zq5e28</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250515_021613-59zq5e28/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7tdf1mct with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250515_025802-7tdf1mct</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/7tdf1mct' target=\"_blank\">jumping-sweep-4</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/sweeps/7zxwuoi9</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/7tdf1mct' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation_attention/runs/7tdf1mct</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 128)\n    (dropout): Dropout(p=0.4, inplace=False)\n    (rnn): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.4, bidirectional=True)\n  )\n  (decoder): AttnDecoder(\n    (embedding): Embedding(63, 128)\n    (dropout): Dropout(p=0.4, inplace=False)\n    (attention): BahdanauAttention(\n      (attn): Linear(in_features=768, out_features=256, bias=True)\n    )\n    (rnn): LSTM(640, 256, batch_first=True, dropout=0.4)\n    (fc): Linear(in_features=256, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.0735, Val Loss: 1.7850, Val Accuracy: 9.2257\nEpoch 2/5, Train Loss: 1.0186, Val Loss: 1.7881, Val Accuracy: 13.8567\nEpoch 3/5, Train Loss: 0.9650, Val Loss: 1.8296, Val Accuracy: 15.2350\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4/5, Train Loss: 0.9444, Val Loss: 1.9001, Val Accuracy: 15.8829\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:11"
      ],
      "metadata": {
        "id": "Q72CiXLvoFGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 29  #30\n",
        "output_size = 63 #70\n",
        "embed_size = 256\n",
        "beam_width=3\n",
        "hidden_size = 128\n",
        "encoder_layers = 3\n",
        "decoder_layers = 1\n",
        "cell_type = 'gru'\n",
        "batch_size = 64\n",
        "num_epochs = 35\n",
        "drop_prob = 0.0\n",
        "learning_rate = 0.001\n",
        "Best_model = Seq2SeqModel(input_size, output_size, hidden_size,embed_size,beam_width, encoder_layers,decoder_layers,drop_prob, cell_type,bidirectional)\n",
        "print(Best_model)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "Best_model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(Best_model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T03:24:41.167348Z",
          "iopub.execute_input": "2025-05-15T03:24:41.167600Z",
          "iopub.status.idle": "2025-05-15T03:24:41.184157Z",
          "shell.execute_reply.started": "2025-05-15T03:24:41.167581Z",
          "shell.execute_reply": "2025-05-15T03:24:41.183434Z"
        },
        "id": "140JZx0Gy9OX",
        "outputId": "16ee3da9-8e00-4114-bf69-f74f03909dce"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 256)\n    (dropout): Dropout(p=0.0, inplace=False)\n    (rnn): GRU(256, 128, num_layers=3, batch_first=True)\n  )\n  (decoder): AttnDecoder(\n    (embedding): Embedding(63, 256)\n    (dropout): Dropout(p=0.0, inplace=False)\n    (attention): BahdanauAttention(\n      (attn): Linear(in_features=256, out_features=128, bias=True)\n    )\n    (rnn): GRU(384, 128, batch_first=True)\n    (fc): Linear(in_features=128, out_features=63, bias=True)\n  )\n)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:12**"
      ],
      "metadata": {
        "id": "JNWbSCdToKps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = Best_model.to(device)\n",
        "for epoch in range(35):\n",
        "    print(f\"\\nEpoch {epoch+1} started.\")\n",
        "    final_model, _ = train_model(final_model, train_loader_ben, criterion, optimizer, device)\n",
        "    print(f\"Finished training for epoch {epoch+1}\")\n",
        "    train_loss, train_accuracy = evaluate_model(final_model, train_loader_ben, criterion, device)\n",
        "    val_loss, val_accuracy = evaluate_model(final_model, val_data_loader, criterion, device)\n",
        "    print(f'Epoch {epoch+1}/35')\n",
        "    print(f' - Train Loss      : {train_loss:.4f}, Train Accuracy      : {train_accuracy:.2f}%')\n",
        "    print(f' - Validation Loss : {val_loss:.4f}, Validation Accuracy : {val_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T03:24:52.272587Z",
          "iopub.execute_input": "2025-05-15T03:24:52.272846Z",
          "iopub.status.idle": "2025-05-15T04:19:53.532648Z",
          "shell.execute_reply.started": "2025-05-15T03:24:52.272826Z",
          "shell.execute_reply": "2025-05-15T04:19:53.531994Z"
        },
        "id": "7JwOQCIjy9OX",
        "outputId": "be039008-948f-4b0d-ad23-314cd25ff945"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nEpoch 1 started.\nFinished training for epoch 1\nEpoch 1/35\n - Train Loss      : 1.4519, Train Accuracy      : 15.06%\n - Validation Loss : 1.7502, Validation Accuracy : 11.50%\n\nEpoch 2 started.\nFinished training for epoch 2\nEpoch 2/35\n - Train Loss      : 1.2743, Train Accuracy      : 21.99%\n - Validation Loss : 1.5841, Validation Accuracy : 18.33%\n\nEpoch 3 started.\nFinished training for epoch 3\nEpoch 3/35\n - Train Loss      : 1.1903, Train Accuracy      : 28.74%\n - Validation Loss : 1.5479, Validation Accuracy : 24.03%\n\nEpoch 4 started.\nFinished training for epoch 4\nEpoch 4/35\n - Train Loss      : 1.2174, Train Accuracy      : 31.58%\n - Validation Loss : 1.5577, Validation Accuracy : 28.36%\n\nEpoch 5 started.\nFinished training for epoch 5\nEpoch 5/35\n - Train Loss      : 1.0777, Train Accuracy      : 40.14%\n - Validation Loss : 1.5336, Validation Accuracy : 33.48%\n\nEpoch 6 started.\nFinished training for epoch 6\nEpoch 6/35\n - Train Loss      : 0.9540, Train Accuracy      : 44.94%\n - Validation Loss : 1.5347, Validation Accuracy : 35.81%\n\nEpoch 7 started.\nFinished training for epoch 7\nEpoch 7/35\n - Train Loss      : 0.9934, Train Accuracy      : 45.13%\n - Validation Loss : 1.5427, Validation Accuracy : 36.81%\n\nEpoch 8 started.\nFinished training for epoch 8\nEpoch 8/35\n - Train Loss      : 1.0605, Train Accuracy      : 45.95%\n - Validation Loss : 1.5613, Validation Accuracy : 38.26%\n\nEpoch 9 started.\nFinished training for epoch 9\nEpoch 9/35\n - Train Loss      : 1.0112, Train Accuracy      : 47.47%\n - Validation Loss : 1.5517, Validation Accuracy : 39.18%\n\nEpoch 10 started.\nFinished training for epoch 10\nEpoch 10/35\n - Train Loss      : 0.9456, Train Accuracy      : 50.24%\n - Validation Loss : 1.6193, Validation Accuracy : 39.32%\n\nEpoch 11 started.\nFinished training for epoch 11\nEpoch 11/35\n - Train Loss      : 0.9064, Train Accuracy      : 52.93%\n - Validation Loss : 1.6421, Validation Accuracy : 38.29%\n\nEpoch 12 started.\nFinished training for epoch 12\nEpoch 12/35\n - Train Loss      : 0.8468, Train Accuracy      : 56.69%\n - Validation Loss : 1.6190, Validation Accuracy : 42.17%\n\nEpoch 13 started.\nFinished training for epoch 13\nEpoch 13/35\n - Train Loss      : 0.8597, Train Accuracy      : 56.45%\n - Validation Loss : 1.6344, Validation Accuracy : 42.82%\n\nEpoch 14 started.\nFinished training for epoch 14\nEpoch 14/35\n - Train Loss      : 0.7904, Train Accuracy      : 57.79%\n - Validation Loss : 1.7196, Validation Accuracy : 40.31%\n\nEpoch 15 started.\nFinished training for epoch 15\nEpoch 15/35\n - Train Loss      : 0.8161, Train Accuracy      : 57.74%\n - Validation Loss : 1.7091, Validation Accuracy : 42.23%\n\nEpoch 16 started.\nFinished training for epoch 16\nEpoch 16/35\n - Train Loss      : 0.7846, Train Accuracy      : 60.18%\n - Validation Loss : 1.7147, Validation Accuracy : 42.30%\n\nEpoch 17 started.\nFinished training for epoch 17\nEpoch 17/35\n - Train Loss      : 0.7573, Train Accuracy      : 61.03%\n - Validation Loss : 1.7177, Validation Accuracy : 43.16%\n\nEpoch 18 started.\nFinished training for epoch 18\nEpoch 18/35\n - Train Loss      : 0.8040, Train Accuracy      : 59.20%\n - Validation Loss : 1.7846, Validation Accuracy : 41.43%\n\nEpoch 19 started.\nFinished training for epoch 19\nEpoch 19/35\n - Train Loss      : 0.7741, Train Accuracy      : 61.11%\n - Validation Loss : 1.7595, Validation Accuracy : 43.34%\n\nEpoch 20 started.\nFinished training for epoch 20\nEpoch 20/35\n - Train Loss      : 0.8882, Train Accuracy      : 57.99%\n - Validation Loss : 1.7833, Validation Accuracy : 42.64%\n\nEpoch 21 started.\nFinished training for epoch 21\nEpoch 21/35\n - Train Loss      : 0.7335, Train Accuracy      : 62.16%\n - Validation Loss : 1.7631, Validation Accuracy : 42.88%\n\nEpoch 22 started.\nFinished training for epoch 22\nEpoch 22/35\n - Train Loss      : 0.7650, Train Accuracy      : 62.48%\n - Validation Loss : 1.7680, Validation Accuracy : 44.20%\n\nEpoch 23 started.\nFinished training for epoch 23\nEpoch 23/35\n - Train Loss      : 0.7173, Train Accuracy      : 64.19%\n - Validation Loss : 1.7705, Validation Accuracy : 44.96%\n\nEpoch 24 started.\nFinished training for epoch 24\nEpoch 24/35\n - Train Loss      : 0.7466, Train Accuracy      : 63.57%\n - Validation Loss : 1.7864, Validation Accuracy : 44.55%\n\nEpoch 25 started.\nFinished training for epoch 25\nEpoch 25/35\n - Train Loss      : 0.6965, Train Accuracy      : 65.09%\n - Validation Loss : 1.7708, Validation Accuracy : 45.71%\n\nEpoch 26 started.\nFinished training for epoch 26\nEpoch 26/35\n - Train Loss      : 0.6894, Train Accuracy      : 65.81%\n - Validation Loss : 1.7660, Validation Accuracy : 45.83%\n\nEpoch 27 started.\nFinished training for epoch 27\nEpoch 27/35\n - Train Loss      : 0.6949, Train Accuracy      : 66.34%\n - Validation Loss : 1.7895, Validation Accuracy : 45.99%\n\nEpoch 28 started.\nFinished training for epoch 28\nEpoch 28/35\n - Train Loss      : 0.6972, Train Accuracy      : 65.64%\n - Validation Loss : 1.7939, Validation Accuracy : 45.46%\n\nEpoch 29 started.\nFinished training for epoch 29\nEpoch 29/35\n - Train Loss      : 0.6918, Train Accuracy      : 66.11%\n - Validation Loss : 1.8329, Validation Accuracy : 45.15%\n\nEpoch 30 started.\nFinished training for epoch 30\nEpoch 30/35\n - Train Loss      : 0.6798, Train Accuracy      : 67.69%\n - Validation Loss : 1.7878, Validation Accuracy : 46.67%\n\nEpoch 31 started.\nFinished training for epoch 31\nEpoch 31/35\n - Train Loss      : 0.7089, Train Accuracy      : 66.61%\n - Validation Loss : 1.8098, Validation Accuracy : 45.93%\n\nEpoch 32 started.\nFinished training for epoch 32\nEpoch 32/35\n - Train Loss      : 0.6303, Train Accuracy      : 69.24%\n - Validation Loss : 1.8149, Validation Accuracy : 46.31%\n\nEpoch 33 started.\nFinished training for epoch 33\nEpoch 33/35\n - Train Loss      : 0.6718, Train Accuracy      : 67.89%\n - Validation Loss : 1.8221, Validation Accuracy : 46.54%\n\nEpoch 34 started.\nFinished training for epoch 34\nEpoch 34/35\n - Train Loss      : 0.6942, Train Accuracy      : 66.60%\n - Validation Loss : 1.8221, Validation Accuracy : 45.61%\n\nEpoch 35 started.\nFinished training for epoch 35\nEpoch 35/35\n - Train Loss      : 0.6784, Train Accuracy      : 67.63%\n - Validation Loss : 1.8243, Validation Accuracy : 45.94%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:13"
      ],
      "metadata": {
        "id": "O8YMjqouoO8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = evaluate_model(final_model,test_data_loader, criterion, device)\n",
        "print(f' Test Accuracy: {test_accuracy:.2f}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T04:19:53.533769Z",
          "iopub.execute_input": "2025-05-15T04:19:53.534189Z",
          "iopub.status.idle": "2025-05-15T04:19:55.788888Z",
          "shell.execute_reply.started": "2025-05-15T04:19:53.534166Z",
          "shell.execute_reply": "2025-05-15T04:19:55.788301Z"
        },
        "id": "zzM-Se5_y9OX",
        "outputId": "27145520-2655-4cf6-ff4b-0a1265050002"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": " Test Accuracy: 45.13\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install -y fonts-noto"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-14T16:13:22.936793Z",
          "iopub.execute_input": "2025-05-14T16:13:22.937527Z",
          "iopub.status.idle": "2025-05-14T16:13:53.468974Z",
          "shell.execute_reply.started": "2025-05-14T16:13:22.937502Z",
          "shell.execute_reply": "2025-05-14T16:13:53.468265Z"
        },
        "id": "4QjjMLpLy9OX",
        "outputId": "5ed0a442-6dd5-4fbe-a486-5cd4b4925a3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  fonts-noto-cjk fonts-noto-cjk-extra fonts-noto-color-emoji fonts-noto-core fonts-noto-extra\n  fonts-noto-ui-core fonts-noto-ui-extra fonts-noto-unhinted\nThe following NEW packages will be installed:\n  fonts-noto fonts-noto-cjk fonts-noto-cjk-extra fonts-noto-color-emoji fonts-noto-core\n  fonts-noto-extra fonts-noto-ui-core fonts-noto-ui-extra fonts-noto-unhinted\n0 upgraded, 9 newly installed, 0 to remove and 161 not upgraded.\nNeed to get 316 MB of archives.\nAfter this operation, 788 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-core all 20201225-1build1 [12.2 MB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-noto all 20201225-1build1 [16.8 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-cjk all 1:20220127+repack1-1 [61.2 MB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-cjk-extra all 1:20220127+repack1-1 [145 MB]\nGet:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 fonts-noto-color-emoji all 2.047-0ubuntu0.22.04.1 [10.0 MB]\nGet:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-noto-extra all 20201225-1build1 [72.4 MB]\nGet:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-ui-core all 20201225-1build1 [1,420 kB]\nGet:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-noto-ui-extra all 20201225-1build1 [14.3 MB]\nGet:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-noto-unhinted all 20201225-1build1 [16.8 kB]\nFetched 316 MB in 7s (43.7 MB/s)                                                                    \nSelecting previously unselected package fonts-noto-core.\n(Reading database ... 128691 files and directories currently installed.)\nPreparing to unpack .../0-fonts-noto-core_20201225-1build1_all.deb ...\nUnpacking fonts-noto-core (20201225-1build1) ...\nSelecting previously unselected package fonts-noto.\nPreparing to unpack .../1-fonts-noto_20201225-1build1_all.deb ...\nUnpacking fonts-noto (20201225-1build1) ...\nSelecting previously unselected package fonts-noto-cjk.\nPreparing to unpack .../2-fonts-noto-cjk_1%3a20220127+repack1-1_all.deb ...\nUnpacking fonts-noto-cjk (1:20220127+repack1-1) ...\nSelecting previously unselected package fonts-noto-cjk-extra.\nPreparing to unpack .../3-fonts-noto-cjk-extra_1%3a20220127+repack1-1_all.deb ...\nUnpacking fonts-noto-cjk-extra (1:20220127+repack1-1) ...\nSelecting previously unselected package fonts-noto-color-emoji.\nPreparing to unpack .../4-fonts-noto-color-emoji_2.047-0ubuntu0.22.04.1_all.deb ...\nUnpacking fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\nSelecting previously unselected package fonts-noto-extra.\nPreparing to unpack .../5-fonts-noto-extra_20201225-1build1_all.deb ...\nUnpacking fonts-noto-extra (20201225-1build1) ...\nSelecting previously unselected package fonts-noto-ui-core.\nPreparing to unpack .../6-fonts-noto-ui-core_20201225-1build1_all.deb ...\nUnpacking fonts-noto-ui-core (20201225-1build1) ...\nSelecting previously unselected package fonts-noto-ui-extra.\nPreparing to unpack .../7-fonts-noto-ui-extra_20201225-1build1_all.deb ...\nUnpacking fonts-noto-ui-extra (20201225-1build1) ...\nSelecting previously unselected package fonts-noto-unhinted.\nPreparing to unpack .../8-fonts-noto-unhinted_20201225-1build1_all.deb ...\nUnpacking fonts-noto-unhinted (20201225-1build1) ...\nSetting up fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\nSetting up fonts-noto-ui-extra (20201225-1build1) ...\nSetting up fonts-noto-extra (20201225-1build1) ...\nSetting up fonts-noto-cjk (1:20220127+repack1-1) ...\nSetting up fonts-noto-unhinted (20201225-1build1) ...\nSetting up fonts-noto-ui-core (20201225-1build1) ...\nSetting up fonts-noto-core (20201225-1build1) ...\nSetting up fonts-noto-cjk-extra (1:20220127+repack1-1) ...\nSetting up fonts-noto (20201225-1build1) ...\nProcessing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:14"
      ],
      "metadata": {
        "id": "D9sleDP8oT9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actual = []\n",
        "    with torch.no_grad():\n",
        "        for latin, devanagari in dataloader:\n",
        "            latin = latin.to(device)\n",
        "            devanagari = devanagari.to(device)\n",
        "            output, _ = model(latin, devanagari, 0)\n",
        "            deb = devanagari.cpu().numpy()\n",
        "            actual.append(deb)\n",
        "            if output.dim() == 3:\n",
        "                output = output.argmax(2)\n",
        "            elif output.dim() == 2:\n",
        "                output = output.argmax(1)\n",
        "            else:\n",
        "                print(\"Unexpected output dimension:\", output.dim())\n",
        "                continue\n",
        "\n",
        "            latin = latin.cpu().numpy()\n",
        "            output = output.cpu().numpy()\n",
        "            predictions.append((latin, output))\n",
        "    return predictions, actual\n",
        "latin_idx2token = {idx: char for char, idx in test_input_letter_vocab.items()}\n",
        "bangla_idx2token = {idx: char for char, idx in test_target_letter_vocab.items()}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T04:20:02.918470Z",
          "iopub.execute_input": "2025-05-15T04:20:02.918997Z",
          "iopub.status.idle": "2025-05-15T04:20:02.924683Z",
          "shell.execute_reply.started": "2025-05-15T04:20:02.918976Z",
          "shell.execute_reply": "2025-05-15T04:20:02.924151Z"
        },
        "id": "xIiMf5KQy9OX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step:15**"
      ],
      "metadata": {
        "id": "lvzaWUqroYtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(indices, idx2token, target_vocab):\n",
        "    valid_indices = []\n",
        "    for idx in indices:\n",
        "        if idx in idx2token and idx not in (target_vocab['<pad>'], target_vocab['<sos>'], target_vocab['<eos>']):\n",
        "            valid_indices.append(idx)\n",
        "    decoded_text = ''\n",
        "    for idx in valid_indices:\n",
        "        decoded_text += idx2token[idx]\n",
        "    return decoded_text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T04:20:05.249694Z",
          "iopub.execute_input": "2025-05-15T04:20:05.250346Z",
          "iopub.status.idle": "2025-05-15T04:20:05.254583Z",
          "shell.execute_reply.started": "2025-05-15T04:20:05.250324Z",
          "shell.execute_reply": "2025-05-15T04:20:05.253841Z"
        },
        "id": "ANN13I9Ny9OX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step;16**"
      ],
      "metadata": {
        "id": "ZyfQl-bWob9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_output_indices(indices, idx2token, target_vocab):\n",
        "    decoded_text = ''\n",
        "    for idx in indices:\n",
        "        if idx == target_vocab.get('<eos>'):\n",
        "            break\n",
        "        if idx in (target_vocab.get('<pad>'), target_vocab.get('<sos>')):\n",
        "            continue\n",
        "        decoded_text += idx2token.get(idx, '')\n",
        "    return decoded_text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T04:20:06.697196Z",
          "iopub.execute_input": "2025-05-15T04:20:06.697859Z",
          "iopub.status.idle": "2025-05-15T04:20:06.701734Z",
          "shell.execute_reply.started": "2025-05-15T04:20:06.697839Z",
          "shell.execute_reply": "2025-05-15T04:20:06.701169Z"
        },
        "id": "wyt_mDpWy9OX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:17**"
      ],
      "metadata": {
        "id": "rWGGRtTnoeqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "test_predictions, actual = run_inference(final_model, test_data_loader, device)\n",
        "seq2seq_results = []\n",
        "for (src_indices, output_indices), act_ind in zip(test_predictions, actual):\n",
        "    for i in range(src_indices.shape[0]):\n",
        "        input_text = decode_sequence(src_indices[i], latin_idx2token, test_input_letter_vocab)\n",
        "        actual_target_text = decode_sequence(act_ind[i], bangla_idx2token, test_target_letter_vocab)\n",
        "        predicted_text = process_output_indices(output_indices[i], bangla_idx2token, test_target_letter_vocab)\n",
        "        seq2seq_results.append([input_text, actual_target_text, predicted_text])\n",
        "results_df = pd.DataFrame(seq2seq_results, columns=[\"Input\", \"Actual\", \"Predicted\"])\n",
        "def char_level_accuracy(actual, predicted):\n",
        "    matches = sum(a == b for a, b in zip(actual, predicted))\n",
        "    return matches / max(len(actual), len(predicted)) if max(len(actual), len(predicted)) > 0 else 0\n",
        "\n",
        "results_df[\"Accuracy\"] = results_df.apply(lambda row: char_level_accuracy(row[\"Actual\"], row[\"Predicted\"]), axis=1)\n",
        "total = len(results_df)\n",
        "count_100 = (results_df[\"Accuracy\"] == 1.0).sum()\n",
        "count_75 = ((results_df[\"Accuracy\"] > 0.75) & (results_df[\"Accuracy\"] < 1.0)).sum()\n",
        "count_50 = ((results_df[\"Accuracy\"] > 0.5) & (results_df[\"Accuracy\"] <= 0.75)).sum()\n",
        "count_25 = ((results_df[\"Accuracy\"] > 0.25) & (results_df[\"Accuracy\"] <= 0.5)).sum()\n",
        "count_0 = (results_df[\"Accuracy\"] <= 0.25).sum()\n",
        "def accuracy_highlighter(row):\n",
        "    acc = row.Accuracy\n",
        "    if acc == 1.0:\n",
        "        color = 'background-color: #d4edda'  # Green\n",
        "    elif acc > 0.75:\n",
        "        color = 'background-color: #cce5ff'  # Light blue\n",
        "    elif acc > 0.5:\n",
        "        color = 'background-color: #fff3cd'  # Light yellow\n",
        "    elif acc > 0.25:\n",
        "        color = 'background-color: #f8d7da'  # Light pink\n",
        "    else:\n",
        "        color = ''  # No color\n",
        "    return [color, color, color, '']\n",
        "\n",
        "# Style the DataFrame\n",
        "styled_table = results_df.style.set_properties(**{\n",
        "    'border': '1px solid black',\n",
        "    'text-align': 'left',\n",
        "    'padding': '6px'\n",
        "}).apply(accuracy_highlighter, axis=1).hide(axis=\"columns\", subset=[\"Accuracy\"])\n",
        "\n",
        "html_content = styled_table.to_html()\n",
        "summary_html = f\"\"\"\n",
        "<div class=\"legend\">\n",
        "    <h3>Prediction Accuracy Summary</h3>\n",
        "    <ul>\n",
        "        <li><strong>Total Predictions:</strong> {total}</li>\n",
        "        <li style=\"background-color: #d4edda; padding: 6px;\">✅ 100% Match: {count_100}</li>\n",
        "        <li style=\"background-color: #cce5ff; padding: 6px;\">✅ Above 75%: {count_75}</li>\n",
        "        <li style=\"background-color: #fff3cd; padding: 6px;\">✅ Above 50%: {count_50}</li>\n",
        "        <li style=\"background-color: #f8d7da; padding: 6px;\">✅ Above 25%: {count_25}</li>\n",
        "        <li>❌ ≤ 25% Match: {count_0}</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\"\"\"\n",
        "html_full = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <title>Seq2Seq Prediction Results</title>\n",
        "    <style>\n",
        "        body {{\n",
        "            font-family: Arial, sans-serif;\n",
        "            background-color: #f5f5f5;\n",
        "            padding: 30px;\n",
        "        }}\n",
        "        h2 {{\n",
        "            text-align: center;\n",
        "            color: #333;\n",
        "        }}\n",
        "        .legend {{\n",
        "            max-width: 600px;\n",
        "            margin: 0 auto 30px auto;\n",
        "            padding: 15px;\n",
        "            border: 1px solid #ccc;\n",
        "            background-color: #fff;\n",
        "        }}\n",
        "        .legend h3 {{\n",
        "            margin-top: 0;\n",
        "        }}\n",
        "        table {{\n",
        "            margin: auto;\n",
        "            border-collapse: collapse;\n",
        "            box-shadow: 0 0 10px rgba(0,0,0,0.1);\n",
        "        }}\n",
        "        th {{\n",
        "            background-color: #4CAF50;\n",
        "            color: white;\n",
        "        }}\n",
        "        td, th {{\n",
        "            padding: 10px 15px;\n",
        "            border: 1px solid #ddd;\n",
        "        }}\n",
        "        tr:nth-child(even) {{\n",
        "            background-color: #f9f9f9;\n",
        "        }}\n",
        "        tr:hover {{\n",
        "            background-color: #f1f1f1;\n",
        "        }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h2>Character-Level Transliteration Predictions using Seq2Seq + Attention</h2>\n",
        "    {summary_html}\n",
        "    {html_content}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "with open(\"predictions_attention.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html_full)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-15T04:20:08.649671Z",
          "iopub.execute_input": "2025-05-15T04:20:08.649943Z",
          "iopub.status.idle": "2025-05-15T04:20:12.813509Z",
          "shell.execute_reply.started": "2025-05-15T04:20:08.649921Z",
          "shell.execute_reply": "2025-05-15T04:20:12.812577Z"
        },
        "id": "1eN_gnVwy9OY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step:18"
      ],
      "metadata": {
        "id": "U8sBuzmqoiMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.rcParams['font.family'] = 'Noto Sans Bengali'\n",
        "import matplotlib.font_manager as fm\n",
        "for font in fm.findSystemFonts(fontpaths=None, fontext='ttf'):\n",
        "    if \"NotoSansBengali\" in font:\n",
        "        print(font)\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "wandb.init()\n",
        "def index_to_word(indices, idx2char):\n",
        "    return ''.join([idx2char[idx] for idx in indices if idx in idx2char and idx2char[idx] not in ['<pad>', '<sos>', '<eos>']])\n",
        "def run_inference_with_attention(model, input_word, input_vocab, target_vocab, idx2input_char, idx2target_char, device, max_input_len, max_target_len):\n",
        "    model.eval()\n",
        "    input_indices = [input_vocab.get(char, input_vocab['<pad>']) for char in input_word]  # Default to <pad> if char not in vocab\n",
        "    input_indices += [input_vocab['<pad>']] * (max_input_len - len(input_indices))  # Padding\n",
        "    input_tensor = torch.tensor(input_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, encoder_hidden = model.encoder(input_tensor)\n",
        "        decoder_hidden = model._init_decoder_hidden(encoder_hidden)\n",
        "        decoder_input = torch.tensor([target_vocab['<sos>']], device=device)  # Start of sequence token\n",
        "\n",
        "        decoded_indices = []\n",
        "        all_attention_weights = []\n",
        "\n",
        "        for _ in range(max_target_len + 2):  # +2 for <sos> and <eos> tokens\n",
        "            decoder_output, decoder_hidden,_ = model.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            top1 = decoder_output.argmax(1)\n",
        "            decoded_indices.append(top1.item())\n",
        "            attention_weights = model.decoder.attention(decoder_hidden[-1], encoder_outputs)\n",
        "            all_attention_weights.append(attention_weights.squeeze(0).cpu().numpy())\n",
        "            if top1.item() == target_vocab['<eos>']:  # End of sequence\n",
        "                break\n",
        "            decoder_input = top1\n",
        "\n",
        "    decoded_word = index_to_word(decoded_indices, idx2target_char)\n",
        "    return decoded_word, all_attention_weights\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "def draw_attention_overlay(input_word, predicted_word, attention_weights):\n",
        "    from matplotlib.font_manager import FontProperties\n",
        "    bengali_font_path = \"/usr/share/fonts/truetype/noto/NotoSansBengali-Regular.ttf\"\n",
        "    bengali_font = FontProperties(fname=bengali_font_path)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(len(input_word) * 0.7, len(predicted_word) * 0.7))\n",
        "    ax.set_xlim(0, len(input_word))\n",
        "    ax.set_ylim(0, len(predicted_word))\n",
        "    ax.axis('off')\n",
        "\n",
        "    for y, out_char in enumerate(predicted_word):\n",
        "        for x, in_char in enumerate(input_word):\n",
        "            weight = attention_weights[y][x]\n",
        "            color_intensity = plt.cm.Greens(weight)\n",
        "            rect = patches.Rectangle((x, len(predicted_word) - y - 1), 1, 1, linewidth=1, edgecolor='white', facecolor=color_intensity)\n",
        "            ax.add_patch(rect)\n",
        "    def is_bengali(char):\n",
        "        return '\\u0980' <= char <= '\\u09FF'\n",
        "    for i, char in enumerate(input_word):\n",
        "        font_prop = bengali_font if is_bengali(char) else None\n",
        "        ax.text(i + 0.5, len(predicted_word) + 0.1, char, ha='center', va='bottom', fontsize=12, fontproperties=font_prop)\n",
        "\n",
        "    for i, char in enumerate(predicted_word):\n",
        "        font_prop = bengali_font if is_bengali(char) else None\n",
        "        ax.text(-0.1, len(predicted_word) - i - 0.5, char, ha='right', va='center', fontsize=12, fontproperties=font_prop)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    wandb.log({\"Attention Connectivity Map\": wandb.Image(fig)})\n",
        "    plt.close(fig)\n",
        "input_words = [ \"erao\", \"ezahar\",\"ejahar\",\"ekatabaddho\",\"eeraneo\"]\n",
        "\n",
        "for input_word in input_words:\n",
        "    predicted_word, attention_weights = run_inference_with_attention(\n",
        "        final_model,\n",
        "        input_word,\n",
        "        test_input_letter_vocab,\n",
        "        test_target_letter_vocab,\n",
        "        latin_idx2token,\n",
        "        bangla_idx2token,\n",
        "        device,\n",
        "        test_max_input_len,\n",
        "        test_max_target_len\n",
        "    )\n",
        "\n",
        "    attention_matrix = np.stack(attention_weights, axis=0)\n",
        "    attention_matrix = attention_matrix[:len(predicted_word), :len(input_word)]\n",
        "\n",
        "    draw_attention_overlay(input_word, predicted_word, attention_matrix)\n",
        "\n",
        "    print(\"Input word:\", input_word)\n",
        "    print(\"Predicted word:\", predicted_word)\n",
        "    print(\"Length of predicted word:\", len(predicted_word))\n",
        "    print(\"Attention shape:\", len(attention_weights), \"x\", len(attention_weights[0]))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-14T16:28:46.741562Z",
          "iopub.execute_input": "2025-05-14T16:28:46.742171Z",
          "iopub.status.idle": "2025-05-14T16:28:56.309347Z",
          "shell.execute_reply.started": "2025-05-14T16:28:46.742147Z",
          "shell.execute_reply": "2025-05-14T16:28:56.308785Z"
        },
        "id": "8s512N6Wy9OY",
        "outputId": "d23f8496-50c1-44a5-f37e-e2309fe3d0b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Light.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-SemiBold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Medium.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-SemiBold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Condensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Bold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Thin.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-SemiCondensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Regular.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Medium.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-ExtraBold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-ExtraCondensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Condensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-ExtraLight.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Black.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Regular.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Thin.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-SemiCondensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Bold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Light.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-ExtraBold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-ExtraLight.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-ExtraCondensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Black.ttf\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250514_162846-6k0qenps</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized/runs/6k0qenps' target=\"_blank\">summer-plant-34</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized/runs/6k0qenps' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized/runs/6k0qenps</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_31/2077466658.py:68: UserWarning: Glyph 108 (l) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_31/2077466658.py:68: UserWarning: Glyph 112 (p) missing from current font.\n  plt.tight_layout()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Input word: erao\nPredicted word: এরাও\nLength of predicted word: 4\nAttention shape: 24 x 22\n--------------------------------------------------\nInput word: ezahar\nPredicted word: এজাহার\nLength of predicted word: 6\nAttention shape: 24 x 22\n--------------------------------------------------\nInput word: ejahar\nPredicted word: এজাহার\nLength of predicted word: 6\nAttention shape: 24 x 22\n--------------------------------------------------\nInput word: ekatabaddho\nPredicted word: একতাবদ্ধ\nLength of predicted word: 8\nAttention shape: 24 x 22\n--------------------------------------------------\nInput word: eeraneo\nPredicted word: ইরানেও\nLength of predicted word: 6\nAttention shape: 24 x 22\n--------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">summer-plant-34</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized/runs/6k0qenps' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized/runs/6k0qenps</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized</a><br>Synced 5 W&B file(s), 5 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250514_162846-6k0qenps/logs</code>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:19**"
      ],
      "metadata": {
        "id": "3NiUIeaWombI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from matplotlib.font_manager import FontProperties\n",
        "import wandb\n",
        "matplotlib.rcParams['font.family'] = 'Noto Sans Bengali'\n",
        "import matplotlib.font_manager as fm\n",
        "for font in fm.findSystemFonts(fontpaths=None, fontext='ttf'):\n",
        "    if \"NotoSansBengali\" in font:\n",
        "        print(font)\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "wandb.init()\n",
        "def index_to_word(indices, idx2char):\n",
        "    return ''.join([idx2char[idx] for idx in indices if idx in idx2char and idx2char[idx] not in ['<pad>', '<sos>', '<eos>']])\n",
        "def run_inference_with_attention(model, input_word, input_vocab, target_vocab, idx2input_char, idx2target_char, device, max_input_len, max_target_len):\n",
        "    model.eval()\n",
        "    input_indices = [input_vocab.get(char, input_vocab['<pad>']) for char in input_word]  # Default to <pad> if char not in vocab\n",
        "    input_indices += [input_vocab['<pad>']] * (max_input_len - len(input_indices))  # Padding\n",
        "    input_tensor = torch.tensor(input_indices, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, encoder_hidden = model.encoder(input_tensor)\n",
        "        decoder_hidden = model._init_decoder_hidden(encoder_hidden)\n",
        "        decoder_input = torch.tensor([target_vocab['<sos>']], device=device)  # Start of sequence token\n",
        "\n",
        "        decoded_indices = []\n",
        "        all_attention_weights = []\n",
        "\n",
        "        for _ in range(max_target_len + 2):  # +2 for <sos> and <eos> tokens\n",
        "            decoder_output, decoder_hidden,_ = model.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            top1 = decoder_output.argmax(1)\n",
        "            decoded_indices.append(top1.item())\n",
        "            attention_weights = model.decoder.attention(decoder_hidden[-1], encoder_outputs)\n",
        "            all_attention_weights.append(attention_weights.squeeze(0).cpu().numpy())\n",
        "            if top1.item() == target_vocab['<eos>']:  # End of sequence\n",
        "                break\n",
        "            decoder_input = top1\n",
        "\n",
        "    decoded_word = index_to_word(decoded_indices, idx2target_char)\n",
        "    return decoded_word, all_attention_weights\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "def draw_model_connectivity(input_word, predicted_word, attention_weights):\n",
        "    from matplotlib.font_manager import FontProperties\n",
        "    bengali_font_path = \"/usr/share/fonts/truetype/noto/NotoSansBengali-Regular.ttf\"\n",
        "    bengali_font = FontProperties(fname=bengali_font_path)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(len(input_word), len(predicted_word)))\n",
        "    ax.set_xlim(0, len(input_word))\n",
        "    ax.set_ylim(0, len(predicted_word))\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Positions for characters\n",
        "    input_positions = [(i + 0.5, len(predicted_word) + 0.5) for i in range(len(input_word))]\n",
        "    output_positions = [(0 - 0.5, len(predicted_word) - i - 0.5) for i in range(len(predicted_word))]\n",
        "\n",
        "    def is_bengali(char):\n",
        "        return '\\u0980' <= char <= '\\u09FF'\n",
        "\n",
        "    # Draw characters\n",
        "    for i, char in enumerate(input_word):\n",
        "        font_prop = bengali_font if is_bengali(char) else None\n",
        "        x, y = input_positions[i]\n",
        "        ax.text(x, y, char, ha='center', va='bottom', fontsize=12, fontproperties=font_prop)\n",
        "\n",
        "    for i, char in enumerate(predicted_word):\n",
        "        font_prop = bengali_font if is_bengali(char) else None\n",
        "        x, y = output_positions[i]\n",
        "        ax.text(x, y, char, ha='right', va='center', fontsize=12, fontproperties=font_prop)\n",
        "\n",
        "    # Draw connections\n",
        "    for out_idx, out_pos in enumerate(output_positions):\n",
        "        for in_idx, in_pos in enumerate(input_positions):\n",
        "            weight = attention_weights[out_idx][in_idx]\n",
        "            line = plt.Line2D(\n",
        "                [in_pos[0], out_pos[0]],\n",
        "                [in_pos[1], out_pos[1]],\n",
        "                linewidth=2 * weight,  # line thickness based on attention\n",
        "                color='green',\n",
        "                alpha=weight  # opacity also based on attention\n",
        "            )\n",
        "            ax.add_line(line)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    wandb.log({\"Model Connectivity Map\": wandb.Image(fig)})\n",
        "    plt.close(fig)\n",
        "input_words = [ \"ejahar\",\"erao\",\"ezahar\",\"ekatabaddho\",\"eeraneo\"]\n",
        "\n",
        "for input_word in input_words:\n",
        "    predicted_word, attention_weights = run_inference_with_attention(\n",
        "        final_model,\n",
        "        input_word,\n",
        "        test_input_letter_vocab,\n",
        "        test_target_letter_vocab,\n",
        "        latin_idx2token,\n",
        "        bangla_idx2token,\n",
        "        device,\n",
        "        test_max_input_len,\n",
        "        test_max_target_len\n",
        "    )\n",
        "\n",
        "    attention_matrix = np.stack(attention_weights, axis=0)\n",
        "    attention_matrix = attention_matrix[:len(predicted_word), :len(input_word)]\n",
        "    draw_model_connectivity(input_word, predicted_word, attention_matrix)\n",
        "    print(\"Input word:\", input_word)\n",
        "    print(\"Predicted word:\", predicted_word)\n",
        "    print(\"Length of predicted word:\", len(predicted_word))\n",
        "    print(\"Attention shape:\", len(attention_weights), \"x\", len(attention_weights[0]))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-14T16:27:19.388403Z",
          "iopub.execute_input": "2025-05-14T16:27:19.388633Z",
          "iopub.status.idle": "2025-05-14T16:27:28.954084Z",
          "shell.execute_reply.started": "2025-05-14T16:27:19.388616Z",
          "shell.execute_reply": "2025-05-14T16:27:28.953463Z"
        },
        "id": "OVx7iFrMy9OY",
        "outputId": "503b81a0-aa93-4a8b-a5c7-bdfb7604adad"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Light.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-SemiBold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Medium.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-SemiBold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Condensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Bold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Thin.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-SemiCondensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Regular.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Medium.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-ExtraBold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-ExtraCondensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Condensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-ExtraLight.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Black.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Regular.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Thin.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-SemiCondensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-Bold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Light.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-ExtraBold.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengaliUI-ExtraLight.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-ExtraCondensed.ttf\n/usr/share/fonts/truetype/noto/NotoSansBengali-Black.ttf\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250514_162719-xwrhykax</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized/runs/xwrhykax' target=\"_blank\">wild-energy-29</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized/runs/xwrhykax' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized/runs/xwrhykax</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_31/2025664938.py:85: UserWarning: Glyph 108 (l) missing from current font.\n  plt.tight_layout()\n/tmp/ipykernel_31/2025664938.py:85: UserWarning: Glyph 112 (p) missing from current font.\n  plt.tight_layout()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Input word: eeraneo\nPredicted word: ইরানেও\nLength of predicted word: 6\nAttention shape: 24 x 22\n--------------------------------------------------\nInput word: ekatabaddho\nPredicted word: একতাবদ্ধ\nLength of predicted word: 8\nAttention shape: 24 x 22\n--------------------------------------------------\nInput word: ejahar\nPredicted word: এজাহার\nLength of predicted word: 6\nAttention shape: 24 x 22\n--------------------------------------------------\nInput word: erao\nPredicted word: এরাও\nLength of predicted word: 4\nAttention shape: 24 x 22\n--------------------------------------------------\nInput word: ezahar\nPredicted word: এজাহার\nLength of predicted word: 6\nAttention shape: 24 x 22\n--------------------------------------------------\nInput word: ekatabaddho\nPredicted word: একতাবদ্ধ\nLength of predicted word: 8\nAttention shape: 24 x 22\n--------------------------------------------------\nInput word: eeraneo\nPredicted word: ইরানেও\nLength of predicted word: 6\nAttention shape: 24 x 22\n--------------------------------------------------\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">wild-energy-29</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized/runs/xwrhykax' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized/runs/xwrhykax</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/uncategorized</a><br>Synced 5 W&B file(s), 7 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250514_162719-xwrhykax/logs</code>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "ZPnx8JK4y9OY"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}