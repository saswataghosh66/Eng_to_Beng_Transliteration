{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11494853,
          "sourceType": "datasetVersion",
          "datasetId": 7205812
        }
      ],
      "dockerImageVersionId": 31012,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Step:1**"
      ],
      "metadata": {
        "id": "sl6-AIB8hrCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path='/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv'\n",
        "valid_data_path='/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv'\n",
        "test_data_path='/kaggle/input/dakshina-dataset/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv'"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T06:20:27.799012Z",
          "iopub.execute_input": "2025-05-18T06:20:27.799821Z",
          "iopub.status.idle": "2025-05-18T06:20:27.803401Z",
          "shell.execute_reply.started": "2025-05-18T06:20:27.799793Z",
          "shell.execute_reply": "2025-05-18T06:20:27.802747Z"
        },
        "id": "3825DUD-LRUQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:2**"
      ],
      "metadata": {
        "id": "5IF69kxuhyo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "def load_and_prepare_data(path, batch_size=32):\n",
        "    df = pd.read_csv(path, delimiter=\"\\t\", header=None)\n",
        "    df.columns = ['target_word', 'input_word', 'dummy']\n",
        "    df = df.drop(columns=['dummy'])\n",
        "    df = df.dropna()\n",
        "    df = df.reset_index(drop=True)\n",
        "    df['input_word'] = df['input_word'].astype(str)\n",
        "    df['target_word'] = df['target_word'].astype(str)\n",
        "\n",
        "    max_input_len = max(len(word) for word in df['input_word'])\n",
        "    max_target_len = max(len(word) for word in df['target_word'])\n",
        "\n",
        "    input_letter_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "    target_letter_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "    letter_idx = 3\n",
        "\n",
        "    for letter in sorted(set(''.join(df['input_word']))):\n",
        "        input_letter_vocab[letter] = letter_idx\n",
        "        letter_idx += 1\n",
        "\n",
        "    letter_idx = 3\n",
        "    for letter in sorted(set(''.join(df['target_word']))):\n",
        "        if letter not in target_letter_vocab:\n",
        "            target_letter_vocab[letter] = letter_idx\n",
        "            letter_idx += 1\n",
        "\n",
        "    def encode_input_letters(word):\n",
        "        token_ids = [input_letter_vocab[char] for char in word if char in input_letter_vocab]\n",
        "        padded = token_ids[:max_input_len] + [input_letter_vocab['<pad>']] * (max_input_len - len(token_ids))\n",
        "        return padded\n",
        "\n",
        "    def encode_target_letters(word):\n",
        "        token_ids = [target_letter_vocab[char] for char in word if char in target_letter_vocab]\n",
        "        padded = [target_letter_vocab['<pad>']] + token_ids[:max_target_len] + [target_letter_vocab['<pad>']] * (max_target_len - len(token_ids))\n",
        "        return padded\n",
        "\n",
        "    input_tensors = [torch.tensor(encode_input_letters(word)) for word in df['input_word']]\n",
        "    target_tensors = [torch.tensor(encode_target_letters(word)) for word in df['target_word']]\n",
        "\n",
        "    input_tensors = torch.stack(input_tensors)\n",
        "    target_tensors = torch.stack(target_tensors)\n",
        "\n",
        "    dataset = TensorDataset(input_tensors, target_tensors)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return dataset, data_loader, input_letter_vocab, target_letter_vocab, max_input_len, max_target_len\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T06:20:29.802923Z",
          "iopub.execute_input": "2025-05-18T06:20:29.803695Z",
          "iopub.status.idle": "2025-05-18T06:20:29.813520Z",
          "shell.execute_reply.started": "2025-05-18T06:20:29.803668Z",
          "shell.execute_reply": "2025-05-18T06:20:29.812776Z"
        },
        "id": "68Q7sUe3LRUR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:3**"
      ],
      "metadata": {
        "id": "qx8HKMVdh5V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset,train_loader_ben,train_input_vocab,train_target_vocab,max_train_input_len,max_train_target_len =load_and_prepare_data(train_data_path,batch_size = 64)\n",
        "print(train_input_vocab,train_target_vocab,max_train_input_len,max_train_target_len)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T06:20:31.980406Z",
          "iopub.execute_input": "2025-05-18T06:20:31.980970Z",
          "iopub.status.idle": "2025-05-18T06:20:34.782297Z",
          "shell.execute_reply.started": "2025-05-18T06:20:31.980941Z",
          "shell.execute_reply": "2025-05-18T06:20:34.781577Z"
        },
        "id": "6IKFWrp4LRUR",
        "outputId": "45c962f4-e59f-44f9-a963-f7d625b7414d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "{'<pad>': 0, '<sos>': 1, '<eos>': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28} {'<pad>': 0, '<sos>': 1, '<eos>': 2, 'ঁ': 3, 'ং': 4, 'ঃ': 5, 'অ': 6, 'আ': 7, 'ই': 8, 'ঈ': 9, 'উ': 10, 'ঊ': 11, 'ঋ': 12, 'এ': 13, 'ঐ': 14, 'ও': 15, 'ঔ': 16, 'ক': 17, 'খ': 18, 'গ': 19, 'ঘ': 20, 'ঙ': 21, 'চ': 22, 'ছ': 23, 'জ': 24, 'ঝ': 25, 'ঞ': 26, 'ট': 27, 'ঠ': 28, 'ড': 29, 'ঢ': 30, 'ণ': 31, 'ত': 32, 'থ': 33, 'দ': 34, 'ধ': 35, 'ন': 36, 'প': 37, 'ফ': 38, 'ব': 39, 'ভ': 40, 'ম': 41, 'য': 42, 'র': 43, 'ল': 44, 'শ': 45, 'ষ': 46, 'স': 47, 'হ': 48, '়': 49, 'া': 50, 'ি': 51, 'ী': 52, 'ু': 53, 'ূ': 54, 'ৃ': 55, 'ে': 56, 'ৈ': 57, 'ো': 58, 'ৌ': 59, '্': 60, 'ৎ': 61, '২': 62} 22 22\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:4**"
      ],
      "metadata": {
        "id": "OavG9tr0iBzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "def load_and_prepare_test_valid_data(path, batch_size=32,\n",
        "                          input_letter_vocab=None,\n",
        "                          target_letter_vocab=None,\n",
        "                          max_input_len=None,\n",
        "                          max_target_len=None):\n",
        "    df = pd.read_csv(path, delimiter=\"\\t\", header=None)\n",
        "    df.columns = ['target_word', 'input_word', 'dummy']\n",
        "    df = df.drop(columns=['dummy'])\n",
        "    df = df.dropna()\n",
        "    df = df.reset_index(drop=True)\n",
        "    df['input_word'] = df['input_word'].astype(str)\n",
        "    df['target_word'] = df['target_word'].astype(str)\n",
        "    if input_letter_vocab is None:\n",
        "        input_letter_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "        letter_idx = 3\n",
        "        for letter in sorted(set(''.join(df['input_word']))):\n",
        "            input_letter_vocab[letter] = letter_idx\n",
        "            letter_idx += 1\n",
        "    if target_letter_vocab is None:\n",
        "        target_letter_vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "        letter_idx = 3\n",
        "        for letter in sorted(set(''.join(df['target_word']))):\n",
        "            if letter not in target_letter_vocab:\n",
        "                target_letter_vocab[letter] = letter_idx\n",
        "                letter_idx += 1\n",
        "    if max_input_len is None:\n",
        "        max_input_len = max(len(word) for word in df['input_word'])\n",
        "    if max_target_len is None:\n",
        "        max_target_len = max(len(word) for word in df['target_word'])\n",
        "    def encode_input_letters(word):\n",
        "        token_ids = [input_letter_vocab[char] for char in word if char in input_letter_vocab]\n",
        "        padded = token_ids[:max_input_len] + [input_letter_vocab['<pad>']] * (max_input_len - len(token_ids))\n",
        "        return padded\n",
        "\n",
        "    def encode_target_letters(word):\n",
        "        token_ids = [target_letter_vocab[char] for char in word if char in target_letter_vocab]\n",
        "        padded = [target_letter_vocab['<sos>']] + token_ids[:max_target_len] + [target_letter_vocab['<eos>']]\n",
        "        padded += [target_letter_vocab['<pad>']] * (max_target_len + 2 - len(padded))\n",
        "        return padded\n",
        "    input_tensors = [torch.tensor(encode_input_letters(word)) for word in df['input_word']]\n",
        "    target_tensors = [torch.tensor(encode_target_letters(word)) for word in df['target_word']]\n",
        "    input_tensors = torch.stack(input_tensors)\n",
        "    target_tensors = torch.stack(target_tensors)\n",
        "    dataset = TensorDataset(input_tensors, target_tensors)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "    return dataset, data_loader, input_letter_vocab, target_letter_vocab, max_input_len, max_target_len"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T06:20:36.237950Z",
          "iopub.execute_input": "2025-05-18T06:20:36.238475Z",
          "iopub.status.idle": "2025-05-18T06:20:36.249092Z",
          "shell.execute_reply.started": "2025-05-18T06:20:36.238450Z",
          "shell.execute_reply": "2025-05-18T06:20:36.248380Z"
        },
        "id": "uAlXybCOLRUR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:5**"
      ],
      "metadata": {
        "id": "wzEpaPChkIor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset, val_data_loader, val_input_letter_vocab, val_target_letter_vocab,val_max_input_len, val_max_target_len=load_and_prepare_test_valid_data(valid_data_path,64,train_input_vocab,train_target_vocab,max_train_input_len,max_train_target_len)\n",
        "test_dataset, test_data_loader, test_input_letter_vocab, test_target_letter_vocab, test_max_input_len, test_max_target_len=load_and_prepare_test_valid_data(test_data_path,64,train_input_vocab,train_target_vocab,max_train_input_len,max_train_target_len)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T06:20:39.453721Z",
          "iopub.execute_input": "2025-05-18T06:20:39.454275Z",
          "iopub.status.idle": "2025-05-18T06:20:39.921510Z",
          "shell.execute_reply.started": "2025-05-18T06:20:39.454253Z",
          "shell.execute_reply": "2025-05-18T06:20:39.920904Z"
        },
        "id": "BHQ7sTPGLRUS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:6**"
      ],
      "metadata": {
        "id": "o6Gq0H0YkOVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, embed_size, encoder_layers=1, drop_prob=0.5, cell_type='gru', bidirectional=False):\n",
        "        super(TextEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, embed_size)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.cell_type = cell_type\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        rnn_cls = {'lstm': nn.LSTM, 'gru': nn.GRU, 'rnn': nn.RNN}[cell_type]\n",
        "        self.rnn = rnn_cls(embed_size, hidden_size, encoder_layers,\n",
        "                           dropout=drop_prob, bidirectional=bidirectional, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        return outputs, hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, embed_size, output_size, decoder_layers=1, drop_prob=0.5, cell_type='gru'):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, embed_size)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "        rnn_cls = {'lstm': nn.LSTM, 'gru': nn.GRU, 'rnn': nn.RNN}[cell_type]\n",
        "        self.rnn = rnn_cls(embed_size, hidden_size, decoder_layers,\n",
        "                           dropout=drop_prob, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = x.unsqueeze(1)\n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        output = self.fc(output.squeeze(1))\n",
        "        return output, hidden\n",
        "\n",
        "class Seq2SeqModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size, embed_size, beam_width,\n",
        "                 encoder_layers=1, decoder_layers=1, drop_prob=0.3, cell_type='gru', bidirectional=True):\n",
        "        super(Seq2SeqModel, self).__init__()\n",
        "        self.encoder = TextEncoder(input_size, hidden_size, embed_size,\n",
        "                                   encoder_layers, drop_prob, cell_type, bidirectional)\n",
        "\n",
        "        self.bidirectional = bidirectional\n",
        "        self.beam_width = beam_width\n",
        "        enc_hidden_size = 2 * hidden_size if bidirectional else hidden_size\n",
        "\n",
        "        self.decoder = Decoder(hidden_size, embed_size, output_size,\n",
        "                               decoder_layers, drop_prob, cell_type)\n",
        "\n",
        "        self.cell_type = cell_type\n",
        "        self.encoder_layers = encoder_layers\n",
        "        self.decoder_layers = decoder_layers\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        batch_size = source.size(0)\n",
        "        target_len = target.size(1)\n",
        "        output_vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, target_len, output_vocab_size).to(source.device)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = self.encoder(source)\n",
        "        decoder_hidden = self._init_decoder_hidden(encoder_hidden)\n",
        "        decoder_input = target[:, 0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            outputs[:, t] = decoder_output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            decoder_input = target[:, t] if teacher_force else decoder_output.argmax(1)\n",
        "\n",
        "        return outputs, None\n",
        "\n",
        "    def _init_decoder_hidden(self, encoder_hidden):\n",
        "        decoder_layers = self.decoder.rnn.num_layers\n",
        "        if self.cell_type == 'lstm':\n",
        "            h, c = encoder_hidden\n",
        "            if self.bidirectional:\n",
        "                h = self._merge_bidirectional(h)\n",
        "                c = self._merge_bidirectional(c)\n",
        "            h = self._pad_or_trim(h, decoder_layers)\n",
        "            c = self._pad_or_trim(c, decoder_layers)\n",
        "            return (h, c)\n",
        "        else:\n",
        "            h = encoder_hidden\n",
        "            if self.bidirectional:\n",
        "                h = self._merge_bidirectional(h)\n",
        "            h = self._pad_or_trim(h, decoder_layers)\n",
        "            return h\n",
        "\n",
        "    def _merge_bidirectional(self, hidden):\n",
        "        return hidden.view(self.encoder.rnn.num_layers, 2, hidden.size(1), hidden.size(2)).sum(1)\n",
        "\n",
        "    def _pad_or_trim(self, hidden, target_layers):\n",
        "        if hidden.shape[0] < target_layers:\n",
        "            pad = torch.zeros(target_layers - hidden.shape[0], *hidden.shape[1:], device=hidden.device)\n",
        "            return torch.cat([hidden, pad], dim=0)\n",
        "        return hidden[:target_layers]\n",
        "\n",
        "    def beam_search_decode(self, source, sos_idx, eos_idx, max_len=50):\n",
        "        device = source.device\n",
        "        batch_size = source.size(0)\n",
        "        assert batch_size == 1, \"Beam search decoding supports batch size 1 for simplicity.\"\n",
        "\n",
        "        encoder_outputs, encoder_hidden = self.encoder(source)\n",
        "        decoder_hidden = self._init_decoder_hidden(encoder_hidden)\n",
        "\n",
        "        beams = [(0.0, [sos_idx], decoder_hidden)]\n",
        "        completed_sequences = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            new_beams = []\n",
        "            for log_prob, seq, hidden in beams:\n",
        "                decoder_input = torch.tensor([[seq[-1]]], device=device)\n",
        "                with torch.no_grad():\n",
        "                    decoder_output, new_hidden = self.decoder(decoder_input, hidden)\n",
        "                    probs = F.log_softmax(decoder_output, dim=1)\n",
        "                    topk_probs, topk_indices = probs.topk(self.beam_width)\n",
        "\n",
        "                for k in range(self.beam_width):\n",
        "                    next_token = topk_indices[0, k].item()\n",
        "                    next_log_prob = log_prob + topk_probs[0, k].item()\n",
        "                    new_seq = seq + [next_token]\n",
        "\n",
        "                    if next_token == eos_idx:\n",
        "                        completed_sequences.append((next_log_prob, new_seq))\n",
        "                    else:\n",
        "                        new_beams.append((next_log_prob, new_seq, new_hidden))\n",
        "\n",
        "            beams = sorted(new_beams, key=lambda x: x[0], reverse=True)[:self.beam_width]\n",
        "\n",
        "            if len(completed_sequences) >= self.beam_width:\n",
        "                break\n",
        "\n",
        "        if not completed_sequences:\n",
        "            completed_sequences = [(log_prob, seq) for log_prob, seq, _ in beams]\n",
        "\n",
        "        completed_sequences = sorted(completed_sequences, key=lambda x: x[0], reverse=True)\n",
        "        best_log_prob, best_seq = completed_sequences[0]\n",
        "        return best_seq, None\n",
        "\n",
        "def train_model(model, data_loader, loss_function, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for input_data, target_data in data_loader:\n",
        "        input_data = input_data.to(device)\n",
        "        target_data = target_data.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions, _ = model(input_data, target_data)\n",
        "        output_size = predictions.shape[-1]\n",
        "        predictions = predictions.view(-1, output_size)\n",
        "        target_data = target_data.view(-1)\n",
        "\n",
        "        loss = loss_function(predictions, target_data)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return model, total_loss / len(data_loader)\n",
        "\n",
        "def evaluate_model(model, data_loader, loss_function, device, pad_token_id=0):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_tokens = 0\n",
        "    correct_tokens = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_data, target_data in data_loader:\n",
        "            input_data = input_data.to(device)\n",
        "            target_data = target_data.to(device)\n",
        "\n",
        "            predictions, _ = model(input_data, target_data, teacher_forcing_ratio=0.0)\n",
        "            output_size = predictions.shape[-1]\n",
        "            loss = loss_function(predictions.view(-1, output_size), target_data.view(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            predicted_tokens = predictions.argmax(dim=-1)\n",
        "            mask = target_data != pad_token_id\n",
        "            correct = (predicted_tokens == target_data) & mask\n",
        "            correct_tokens += correct.sum().item()\n",
        "            total_tokens += mask.sum().item()\n",
        "\n",
        "    average_loss = total_loss / len(data_loader)\n",
        "    accuracy = correct_tokens / total_tokens if total_tokens > 0 else 0.0\n",
        "    return average_loss, accuracy * 100"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T06:20:41.882130Z",
          "iopub.execute_input": "2025-05-18T06:20:41.882763Z",
          "iopub.status.idle": "2025-05-18T06:20:41.905982Z",
          "shell.execute_reply.started": "2025-05-18T06:20:41.882740Z",
          "shell.execute_reply": "2025-05-18T06:20:41.905125Z"
        },
        "id": "RQSM9L5bLRUS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:7**"
      ],
      "metadata": {
        "id": "cq-xamZwkTnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import numpy as np\n",
        "from types import SimpleNamespace\n",
        "import random"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T06:20:47.420073Z",
          "iopub.execute_input": "2025-05-18T06:20:47.420906Z",
          "iopub.status.idle": "2025-05-18T06:20:50.201790Z",
          "shell.execute_reply.started": "2025-05-18T06:20:47.420872Z",
          "shell.execute_reply": "2025-05-18T06:20:50.201183Z"
        },
        "id": "tb84giXALRUS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "api_key = getpass.getpass(\"Enter your W&B API Key: \")\n",
        "wandb.login(key=api_key)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T06:21:19.914199Z",
          "iopub.execute_input": "2025-05-18T06:21:19.914510Z",
          "iopub.status.idle": "2025-05-18T06:21:28.371911Z",
          "shell.execute_reply.started": "2025-05-18T06:21:19.914488Z",
          "shell.execute_reply": "2025-05-18T06:21:28.371341Z"
        },
        "id": "3sY6PPTqLRUS",
        "outputId": "aecfc9b9-8bd4-4d2b-a146-5b9b6fd571b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Enter your W&B API Key:  ········\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma24m022\u001b[0m (\u001b[33mma24m022-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
          "output_type": "stream"
        },
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:8**"
      ],
      "metadata": {
        "id": "2sMYIzOxkc7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'embedding_size': {\n",
        "            'values': [256, 192, 128, 64, 32]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.0,0.1,0.2,0.3,0.4,0.5]\n",
        "        },\n",
        "        'encoder_layers': {\n",
        "            'values': [1,2,3]\n",
        "        },\n",
        "        'decoder_layers': {\n",
        "            'values': [1,2,3]\n",
        "        },\n",
        "        'hidden_layer_size': {\n",
        "            'values': [512, 256, 192, 128, 64]\n",
        "        },\n",
        "        'cell_type': {\n",
        "            'values': ['lstm', 'rnn', 'gru']\n",
        "        },\n",
        "        'bidirectional': {\n",
        "            'values': [True, False]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [128, 64, 32, 16]\n",
        "        },\n",
        "        'num_epochs': {\n",
        "            'values': [5]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [0.0001, 0.001, 0.005, 0.01]\n",
        "        },\n",
        "         'beam_width': {\n",
        "            'values': [10, 5, 3, 2, 1]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='DL_Translation')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T06:21:32.337238Z",
          "iopub.execute_input": "2025-05-18T06:21:32.337515Z",
          "iopub.status.idle": "2025-05-18T06:21:32.593984Z",
          "shell.execute_reply.started": "2025-05-18T06:21:32.337495Z",
          "shell.execute_reply": "2025-05-18T06:21:32.593342Z"
        },
        "id": "CLhfkRv4LRUS",
        "outputId": "de81e141-0837-4fdf-84f3-a06692609cf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Create sweep with ID: is1xsx5h\nSweep URL: https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:9**"
      ],
      "metadata": {
        "id": "b0hNhGuZkhmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    with wandb.init() as run:\n",
        "        run_name=\"ct-\"+str(wandb.config.cell_type)+\"_el-\"+str(wandb.config.encoder_layers)+\"_dl-\"+str(wandb.config.decoder_layers)+\"_drop-\"+str(wandb.config.dropout)+\"_es-\"+str(wandb.config.embedding_size)+\"_hs-\"+str(wandb.config.hidden_layer_size)+\"_bs-\"+str(wandb.config.batch_size)+\"_ep-\"+str(wandb.config.num_epochs)+\"lr\"+str(wandb.config.learning_rate)\n",
        "        wandb.run.name=run_name\n",
        "\n",
        "        model = Seq2SeqModel(input_size=29, output_size=63, hidden_size=wandb.config.hidden_layer_size,embed_size=wandb.config.embedding_size,beam_width=wandb.config.beam_width,encoder_layers=wandb.config.encoder_layers,\n",
        "                        decoder_layers=wandb.config.decoder_layers,drop_prob=wandb.config.dropout, cell_type=wandb.config.cell_type, bidirectional=wandb.config.bidirectional)\n",
        "        print(model)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=wandb.config.learning_rate)\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "        custom_dataset1,train_loader_ben,a,b,_,_ = load_and_prepare_data(train_data_path,batch_size = wandb.config.batch_size)\n",
        "        custom_dataset,val_loader_ben,_,_,_,_ =load_and_prepare_data(valid_data_path,batch_size = wandb.config.batch_size)\n",
        "        for epoch in range(wandb.config.num_epochs):\n",
        "            trained_model, train_loss = train_model(model, train_loader_ben, criterion, optimizer, device)\n",
        "            val_loss, val_accuracy = evaluate_model(trained_model,val_data_loader, criterion, device)\n",
        "            model = trained_model\n",
        "            wandb.log({'Epoch': epoch, 'train_loss': train_loss , ' val_loss': val_loss, 'val_accuracy':val_accuracy})\n",
        "            print(f'Epoch {epoch+1}/{wandb.config.num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
        "wandb.agent(sweep_id, function= main,count=15)\n",
        "# wandb.finish()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T06:21:35.043392Z",
          "iopub.execute_input": "2025-05-18T06:21:35.043655Z",
          "iopub.status.idle": "2025-05-18T09:51:04.312237Z",
          "shell.execute_reply.started": "2025-05-18T06:21:35.043636Z",
          "shell.execute_reply": "2025-05-18T09:51:04.311496Z"
        },
        "id": "xb14c9KNLRUS",
        "outputId": "5b46acf5-1427-4230-c2f1-572267e7ab85"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: k2t8ani9 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_062141-k2t8ani9</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/k2t8ani9' target=\"_blank\">generous-sweep-1</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/k2t8ani9' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/k2t8ani9</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 128)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (rnn): LSTM(128, 512, num_layers=3, batch_first=True, dropout=0.1, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 128)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (rnn): LSTM(128, 512, num_layers=2, batch_first=True, dropout=0.1)\n    (fc): Linear(in_features=512, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.1670, Val Loss: 1.6708, Val Accuracy: 14.2717\nEpoch 2/5, Train Loss: 0.9251, Val Loss: 1.5821, Val Accuracy: 18.6613\nEpoch 3/5, Train Loss: 0.7578, Val Loss: 1.5518, Val Accuracy: 21.8558\nEpoch 4/5, Train Loss: 0.6486, Val Loss: 1.5401, Val Accuracy: 26.1459\nEpoch 5/5, Train Loss: 0.5715, Val Loss: 1.5499, Val Accuracy: 30.0332\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>█▃▂▁▂</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▅▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>1.54994</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.57152</td></tr><tr><td>val_accuracy</td><td>30.03324</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-lstm_el-3_dl-2_drop-0.1_es-128_hs-512_bs-32_ep-5lr0.0001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/k2t8ani9' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/k2t8ani9</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_062141-k2t8ani9/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8jyn0gvv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_063711-8jyn0gvv</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/8jyn0gvv' target=\"_blank\">daily-sweep-2</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/8jyn0gvv' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/8jyn0gvv</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 32)\n    (dropout): Dropout(p=0.4, inplace=False)\n    (rnn): LSTM(32, 256, batch_first=True, dropout=0.4)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 32)\n    (dropout): Dropout(p=0.4, inplace=False)\n    (rnn): LSTM(32, 256, batch_first=True, dropout=0.4)\n    (fc): Linear(in_features=256, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.1245, Val Loss: 1.8845, Val Accuracy: 7.0406\nEpoch 2/5, Train Loss: 1.0449, Val Loss: 1.9984, Val Accuracy: 9.7668\nEpoch 3/5, Train Loss: 0.9800, Val Loss: 2.0912, Val Accuracy: 10.0544\nEpoch 4/5, Train Loss: 0.9365, Val Loss: 2.2039, Val Accuracy: 10.3698\nEpoch 5/5, Train Loss: 0.8930, Val Loss: 2.1727, Val Accuracy: 12.1788\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▁▃▆█▇</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▆▄▂▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>2.1727</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.893</td></tr><tr><td>val_accuracy</td><td>12.17879</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-lstm_el-1_dl-1_drop-0.4_es-32_hs-256_bs-16_ep-5lr0.001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/8jyn0gvv' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/8jyn0gvv</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_063711-8jyn0gvv/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6ascm9tk with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_065352-6ascm9tk</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/6ascm9tk' target=\"_blank\">devoted-sweep-3</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/6ascm9tk' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/6ascm9tk</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 32)\n    (dropout): Dropout(p=0.5, inplace=False)\n    (rnn): LSTM(32, 64, num_layers=3, batch_first=True, dropout=0.5, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 32)\n    (dropout): Dropout(p=0.5, inplace=False)\n    (rnn): LSTM(32, 64, batch_first=True, dropout=0.5)\n    (fc): Linear(in_features=64, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.0821, Val Loss: 2.0259, Val Accuracy: 7.2687\nEpoch 2/5, Train Loss: 1.0782, Val Loss: 2.1355, Val Accuracy: 6.8040\nEpoch 3/5, Train Loss: 1.0858, Val Loss: 2.1997, Val Accuracy: 8.2187\nEpoch 4/5, Train Loss: 1.0850, Val Loss: 2.3844, Val Accuracy: 7.6691\nEpoch 5/5, Train Loss: 1.0866, Val Loss: 2.4973, Val Accuracy: 8.8484\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▁▃▄▆█</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>▄▁▇▇█</td></tr><tr><td>val_accuracy</td><td>▃▁▆▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>2.49728</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>1.08661</td></tr><tr><td>val_accuracy</td><td>8.84837</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-lstm_el-3_dl-1_drop-0.5_es-32_hs-64_bs-16_ep-5lr0.01</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/6ascm9tk' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/6ascm9tk</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_065352-6ascm9tk/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w5fwau0g with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_071033-w5fwau0g</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/w5fwau0g' target=\"_blank\">restful-sweep-4</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/w5fwau0g' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/w5fwau0g</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 64)\n    (dropout): Dropout(p=0.5, inplace=False)\n    (rnn): LSTM(64, 256, batch_first=True, dropout=0.5)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 64)\n    (dropout): Dropout(p=0.5, inplace=False)\n    (rnn): LSTM(64, 256, batch_first=True, dropout=0.5)\n    (fc): Linear(in_features=256, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.3391, Val Loss: 1.6487, Val Accuracy: 6.3466\nEpoch 2/5, Train Loss: 1.1970, Val Loss: 1.6579, Val Accuracy: 7.8353\nEpoch 3/5, Train Loss: 1.1544, Val Loss: 1.6888, Val Accuracy: 8.0051\nEpoch 4/5, Train Loss: 1.1109, Val Loss: 1.7070, Val Accuracy: 9.9694\nEpoch 5/5, Train Loss: 1.0704, Val Loss: 1.6684, Val Accuracy: 11.8937\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▁▂▆█▃</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>1.66836</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>1.07037</td></tr><tr><td>val_accuracy</td><td>11.89367</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-lstm_el-1_dl-1_drop-0.5_es-64_hs-256_bs-128_ep-5lr0.001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/w5fwau0g' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/w5fwau0g</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_071033-w5fwau0g/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dm9wtx78 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_071330-dm9wtx78</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/dm9wtx78' target=\"_blank\">frosty-sweep-5</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/dm9wtx78' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/dm9wtx78</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): RNN(64, 256, num_layers=3, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): RNN(64, 256, num_layers=3, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=256, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.2124, Val Loss: 2.0543, Val Accuracy: 3.8800\nEpoch 2/5, Train Loss: 1.1657, Val Loss: 2.0482, Val Accuracy: 4.8409\nEpoch 3/5, Train Loss: 1.1447, Val Loss: 2.1122, Val Accuracy: 4.6019\nEpoch 4/5, Train Loss: 1.1334, Val Loss: 2.1230, Val Accuracy: 4.8409\nEpoch 5/5, Train Loss: 1.1209, Val Loss: 2.1715, Val Accuracy: 6.0615\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▁▁▅▅█</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▄▃▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>2.17153</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>1.1209</td></tr><tr><td>val_accuracy</td><td>6.06149</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-rnn_el-3_dl-3_drop-0.2_es-64_hs-256_bs-16_ep-5lr0.0001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/dm9wtx78' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/dm9wtx78</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_071330-dm9wtx78/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pvcao9da with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 10\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_073125-pvcao9da</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/pvcao9da' target=\"_blank\">lucky-sweep-6</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/pvcao9da' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/pvcao9da</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 64)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (rnn): LSTM(64, 256, num_layers=3, batch_first=True, dropout=0.1)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 64)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (rnn): LSTM(64, 256, num_layers=3, batch_first=True, dropout=0.1)\n    (fc): Linear(in_features=256, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.2940, Val Loss: 1.7062, Val Accuracy: 7.5720\nEpoch 2/5, Train Loss: 1.1600, Val Loss: 1.7622, Val Accuracy: 9.3592\nEpoch 3/5, Train Loss: 1.1009, Val Loss: 1.8186, Val Accuracy: 9.2961\nEpoch 4/5, Train Loss: 1.0658, Val Loss: 1.8763, Val Accuracy: 9.7680\nEpoch 5/5, Train Loss: 1.0386, Val Loss: 1.9767, Val Accuracy: 10.3298\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▁▂▄▅█</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▆▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>1.97666</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>1.03861</td></tr><tr><td>val_accuracy</td><td>10.32977</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-lstm_el-3_dl-3_drop-0.1_es-64_hs-256_bs-32_ep-5lr0.0001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/pvcao9da' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/pvcao9da</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_073125-pvcao9da/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t3my86lv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 192\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_074545-t3my86lv</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/t3my86lv' target=\"_blank\">crimson-sweep-7</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/t3my86lv' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/t3my86lv</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 192)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(192, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 192)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(192, 128, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=128, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.1045, Val Loss: 1.4995, Val Accuracy: 16.8802\nEpoch 2/5, Train Loss: 0.8800, Val Loss: 1.4398, Val Accuracy: 19.9158\nEpoch 3/5, Train Loss: 0.7807, Val Loss: 1.4236, Val Accuracy: 23.4634\nEpoch 4/5, Train Loss: 0.7210, Val Loss: 1.4044, Val Accuracy: 26.8508\nEpoch 5/5, Train Loss: 0.6809, Val Loss: 1.4193, Val Accuracy: 29.0359\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>█▄▂▁▂</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>1.4193</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.6809</td></tr><tr><td>val_accuracy</td><td>29.03594</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-lstm_el-2_dl-1_drop-0.2_es-192_hs-128_bs-64_ep-5lr0.001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/t3my86lv' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/t3my86lv</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_074545-t3my86lv/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r3syosu7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_075022-r3syosu7</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/r3syosu7' target=\"_blank\">summer-sweep-8</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/r3syosu7' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/r3syosu7</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): RNN(64, 128, num_layers=3, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 64)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): RNN(64, 128, num_layers=2, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=128, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.2786, Val Loss: 1.9334, Val Accuracy: 5.5932\nEpoch 2/5, Train Loss: 1.1891, Val Loss: 2.0562, Val Accuracy: 5.5932\nEpoch 3/5, Train Loss: 1.1649, Val Loss: 2.1248, Val Accuracy: 5.1006\nEpoch 4/5, Train Loss: 1.1544, Val Loss: 2.2015, Val Accuracy: 5.6211\nEpoch 5/5, Train Loss: 1.1459, Val Loss: 2.2767, Val Accuracy: 5.2425\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▁▄▅▆█</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr><tr><td>val_accuracy</td><td>██▁█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>2.27674</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>1.14593</td></tr><tr><td>val_accuracy</td><td>5.24253</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-rnn_el-3_dl-2_drop-0.2_es-64_hs-128_bs-16_ep-5lr0.0001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/r3syosu7' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/r3syosu7</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_075022-r3syosu7/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0qves886 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_080558-0qves886</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/0qves886' target=\"_blank\">playful-sweep-9</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/0qves886' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/0qves886</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 128)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(128, 512, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 128)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(128, 512, num_layers=2, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=512, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.0702, Val Loss: 1.7160, Val Accuracy: 14.3081\nEpoch 2/5, Train Loss: 0.8010, Val Loss: 1.6474, Val Accuracy: 20.3574\nEpoch 3/5, Train Loss: 0.6393, Val Loss: 1.6386, Val Accuracy: 26.3376\nEpoch 4/5, Train Loss: 0.5435, Val Loss: 1.6956, Val Accuracy: 29.6717\nEpoch 5/5, Train Loss: 0.4808, Val Loss: 1.7281, Val Accuracy: 31.6517\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▇▂▁▅█</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▅▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>1.72807</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.48083</td></tr><tr><td>val_accuracy</td><td>31.65174</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-lstm_el-3_dl-2_drop-0.2_es-128_hs-512_bs-16_ep-5lr0.0001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/0qves886' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/0qves886</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_080558-0qves886/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 14s258wa with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 192\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_083422-14s258wa</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/14s258wa' target=\"_blank\">trim-sweep-10</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/14s258wa' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/14s258wa</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 192)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): RNN(192, 64, num_layers=2, batch_first=True, dropout=0.3)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 192)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): RNN(192, 64, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=64, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.2621, Val Loss: 7.3271, Val Accuracy: 0.0000\nEpoch 2/5, Train Loss: 1.2097, Val Loss: 2.0700, Val Accuracy: 4.6335\nEpoch 3/5, Train Loss: 1.2065, Val Loss: 2.3000, Val Accuracy: 4.7512\nEpoch 4/5, Train Loss: 1.1978, Val Loss: 2.1079, Val Accuracy: 6.9205\nEpoch 5/5, Train Loss: 1.1886, Val Loss: 2.5584, Val Accuracy: 1.5530\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>█▁▁▁▂</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▃▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▆▆█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>2.55839</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>1.18862</td></tr><tr><td>val_accuracy</td><td>1.55298</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-rnn_el-2_dl-1_drop-0.3_es-192_hs-64_bs-32_ep-5lr0.001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/14s258wa' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/14s258wa</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_083422-14s258wa/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 05ph0owe with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 192\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_084124-05ph0owe</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/05ph0owe' target=\"_blank\">golden-sweep-11</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/05ph0owe' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/05ph0owe</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 192)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): RNN(192, 64, num_layers=3, batch_first=True, dropout=0.2)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 192)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): RNN(192, 64, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=64, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.7158, Val Loss: 1.7229, Val Accuracy: 6.8817\nEpoch 2/5, Train Loss: 1.3697, Val Loss: 1.7854, Val Accuracy: 6.8768\nEpoch 3/5, Train Loss: 1.3254, Val Loss: 1.8110, Val Accuracy: 6.9071\nEpoch 4/5, Train Loss: 1.3021, Val Loss: 1.8433, Val Accuracy: 6.9071\nEpoch 5/5, Train Loss: 1.2834, Val Loss: 1.9004, Val Accuracy: 6.8817\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▁▃▄▆█</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▂▁██▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>1.90045</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>1.28341</td></tr><tr><td>val_accuracy</td><td>6.88166</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-rnn_el-3_dl-1_drop-0.2_es-192_hs-64_bs-64_ep-5lr0.0001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/05ph0owe' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/05ph0owe</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_084124-05ph0owe/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: st7lihyf with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_084516-st7lihyf</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/st7lihyf' target=\"_blank\">gallant-sweep-12</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/st7lihyf' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/st7lihyf</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 64)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): RNN(64, 256, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 64)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): RNN(64, 256, num_layers=3, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=256, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.2132, Val Loss: 2.1782, Val Accuracy: 5.0278\nEpoch 2/5, Train Loss: 1.2048, Val Loss: 2.2743, Val Accuracy: 5.6587\nEpoch 3/5, Train Loss: 1.1996, Val Loss: 2.4859, Val Accuracy: 5.8795\nEpoch 4/5, Train Loss: 1.1953, Val Loss: 3.2902, Val Accuracy: 5.4148\nEpoch 5/5, Train Loss: 1.2063, Val Loss: 2.0636, Val Accuracy: 4.2440\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▂▂▃█▁</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▅▃▁▅</td></tr><tr><td>val_accuracy</td><td>▄▇█▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>2.06357</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>1.20625</td></tr><tr><td>val_accuracy</td><td>4.24401</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-rnn_el-3_dl-3_drop-0.3_es-64_hs-256_bs-16_ep-5lr0.001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/st7lihyf' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/st7lihyf</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_084516-st7lihyf/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 067gpqm7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 192\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_090337-067gpqm7</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/067gpqm7' target=\"_blank\">hardy-sweep-13</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/067gpqm7' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/067gpqm7</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 192)\n    (dropout): Dropout(p=0.4, inplace=False)\n    (rnn): RNN(192, 256, num_layers=3, batch_first=True, dropout=0.4, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 192)\n    (dropout): Dropout(p=0.4, inplace=False)\n    (rnn): RNN(192, 256, num_layers=2, batch_first=True, dropout=0.4)\n    (fc): Linear(in_features=256, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.2287, Val Loss: 2.0408, Val Accuracy: 3.9735\nEpoch 2/5, Train Loss: 1.1897, Val Loss: 2.1313, Val Accuracy: 5.8213\nEpoch 3/5, Train Loss: 1.1595, Val Loss: 2.1818, Val Accuracy: 3.9917\nEpoch 4/5, Train Loss: 1.2045, Val Loss: 2.2627, Val Accuracy: 4.4721\nEpoch 5/5, Train Loss: 1.1955, Val Loss: 2.6668, Val Accuracy: 3.1982\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▁▂▃▃█</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▄▁▆▅</td></tr><tr><td>val_accuracy</td><td>▃█▃▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>2.66684</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>1.19547</td></tr><tr><td>val_accuracy</td><td>3.19818</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-rnn_el-3_dl-2_drop-0.4_es-192_hs-256_bs-32_ep-5lr0.001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/067gpqm7' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/067gpqm7</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_090337-067gpqm7/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bihbeo5c with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 192\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_091215-bihbeo5c</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/bihbeo5c' target=\"_blank\">worthy-sweep-14</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/bihbeo5c' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/bihbeo5c</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 192)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(192, 128, num_layers=3, batch_first=True, dropout=0.3, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 192)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(192, 128, num_layers=2, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=128, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.0519, Val Loss: 1.6233, Val Accuracy: 14.4063\nEpoch 2/5, Train Loss: 0.8435, Val Loss: 1.5272, Val Accuracy: 20.8342\nEpoch 3/5, Train Loss: 0.7381, Val Loss: 1.4867, Val Accuracy: 25.8535\nEpoch 4/5, Train Loss: 0.6729, Val Loss: 1.4817, Val Accuracy: 29.4218\nEpoch 5/5, Train Loss: 0.6223, Val Loss: 1.5364, Val Accuracy: 31.5523\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>█▃▁▁▄</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▅▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>1.53637</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.62232</td></tr><tr><td>val_accuracy</td><td>31.55226</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-lstm_el-3_dl-2_drop-0.3_es-192_hs-128_bs-32_ep-5lr0.001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/bihbeo5c' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/bihbeo5c</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_091215-bihbeo5c/logs</code>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: glub3fmp with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250518_092339-glub3fmp</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/glub3fmp' target=\"_blank\">bumbling-sweep-15</a></strong> to <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/sweeps/is1xsx5h</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/glub3fmp' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/glub3fmp</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 128)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.3)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 128)\n    (dropout): Dropout(p=0.3, inplace=False)\n    (rnn): LSTM(128, 256, num_layers=3, batch_first=True, dropout=0.3)\n    (fc): Linear(in_features=256, out_features=63, bias=True)\n  )\n)\nEpoch 1/5, Train Loss: 1.0789, Val Loss: 2.0595, Val Accuracy: 7.3949\nEpoch 2/5, Train Loss: 0.9829, Val Loss: 2.0825, Val Accuracy: 9.5642\nEpoch 3/5, Train Loss: 0.9169, Val Loss: 2.1210, Val Accuracy: 11.6692\nEpoch 4/5, Train Loss: 0.8435, Val Loss: 2.2055, Val Accuracy: 13.0936\nEpoch 5/5, Train Loss: 0.7789, Val Loss: 2.3384, Val Accuracy: 13.6832\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>▁▂▃▅█</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▆▄▃▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td> val_loss</td><td>2.33838</td></tr><tr><td>Epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.77888</td></tr><tr><td>val_accuracy</td><td>13.68324</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">ct-lstm_el-3_dl-3_drop-0.3_es-128_hs-256_bs-16_ep-5lr0.001</strong> at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/glub3fmp' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation/runs/glub3fmp</a><br> View project at: <a href='https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation' target=\"_blank\">https://wandb.ai/ma24m022-indian-institute-of-technology-madras/DL_Translation</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250518_092339-glub3fmp/logs</code>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:10**"
      ],
      "metadata": {
        "id": "WuD0VU3hkmvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 29\n",
        "output_size = 63\n",
        "embed_size = 128\n",
        "beam_width=5\n",
        "hidden_size = 512\n",
        "encoder_layers = 3\n",
        "decoder_layers = 2\n",
        "cell_type = 'lstm'\n",
        "drop_prob = 0.2\n",
        "learning_rate = 0.0001\n",
        "bidirectional=True\n",
        "batch_size = 16\n",
        "num_epochs = 35\n",
        "Best_model = Seq2SeqModel(input_size, output_size, hidden_size,embed_size,beam_width, encoder_layers,decoder_layers,drop_prob, cell_type,bidirectional)\n",
        "print(Best_model)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "Best_model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(Best_model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T09:59:44.587080Z",
          "iopub.execute_input": "2025-05-18T09:59:44.587681Z",
          "iopub.status.idle": "2025-05-18T09:59:44.742094Z",
          "shell.execute_reply.started": "2025-05-18T09:59:44.587657Z",
          "shell.execute_reply": "2025-05-18T09:59:44.741316Z"
        },
        "id": "L1cIQA2ILRUT",
        "outputId": "0d1aafec-aab1-4eed-d3ed-4d9b46839f7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Seq2SeqModel(\n  (encoder): TextEncoder(\n    (embedding): Embedding(29, 128)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(128, 512, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(63, 128)\n    (dropout): Dropout(p=0.2, inplace=False)\n    (rnn): LSTM(128, 512, num_layers=2, batch_first=True, dropout=0.2)\n    (fc): Linear(in_features=512, out_features=63, bias=True)\n  )\n)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:11**"
      ],
      "metadata": {
        "id": "8hW0hR-fku0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = Best_model.to(device)\n",
        "for epoch in range(35):\n",
        "    print(f\"\\nEpoch {epoch+1} started.\")\n",
        "    final_model, _ = train_model(final_model, train_loader_ben, criterion, optimizer, device)\n",
        "    print(f\"Finished training for epoch {epoch+1}\")\n",
        "    train_loss, train_accuracy = evaluate_model(final_model, train_loader_ben, criterion, device)\n",
        "    val_loss, val_accuracy = evaluate_model(final_model, val_data_loader, criterion, device)\n",
        "    print(f'Epoch {epoch+1}/35')\n",
        "    print(f' - Train Loss      : {train_loss:.4f}, Train Accuracy      : {train_accuracy:.2f}%')\n",
        "    print(f' - Validation Loss : {val_loss:.4f}, Validation Accuracy : {val_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T09:59:49.243127Z",
          "iopub.execute_input": "2025-05-18T09:59:49.243675Z",
          "iopub.status.idle": "2025-05-18T11:28:51.682135Z",
          "shell.execute_reply.started": "2025-05-18T09:59:49.243649Z",
          "shell.execute_reply": "2025-05-18T11:28:51.681437Z"
        },
        "id": "TDjb63xGLRUT",
        "outputId": "4e597ce5-94cc-4cdb-c607-c11a9e2e97b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nEpoch 1 started.\nFinished training for epoch 1\nEpoch 1/35\n - Train Loss      : 1.3527, Train Accuracy      : 10.99%\n - Validation Loss : 1.6545, Validation Accuracy : 8.74%\n\nEpoch 2 started.\nFinished training for epoch 2\nEpoch 2/35\n - Train Loss      : 1.2575, Train Accuracy      : 17.55%\n - Validation Loss : 1.5851, Validation Accuracy : 14.04%\n\nEpoch 3 started.\nFinished training for epoch 3\nEpoch 3/35\n - Train Loss      : 1.1505, Train Accuracy      : 23.09%\n - Validation Loss : 1.5164, Validation Accuracy : 18.13%\n\nEpoch 4 started.\nFinished training for epoch 4\nEpoch 4/35\n - Train Loss      : 1.0531, Train Accuracy      : 27.86%\n - Validation Loss : 1.4615, Validation Accuracy : 22.30%\n\nEpoch 5 started.\nFinished training for epoch 5\nEpoch 5/35\n - Train Loss      : 0.9910, Train Accuracy      : 31.70%\n - Validation Loss : 1.4300, Validation Accuracy : 24.83%\n\nEpoch 6 started.\nFinished training for epoch 6\nEpoch 6/35\n - Train Loss      : 0.9378, Train Accuracy      : 36.32%\n - Validation Loss : 1.4165, Validation Accuracy : 28.33%\n\nEpoch 7 started.\nFinished training for epoch 7\nEpoch 7/35\n - Train Loss      : 0.8945, Train Accuracy      : 40.03%\n - Validation Loss : 1.4324, Validation Accuracy : 30.48%\n\nEpoch 8 started.\nFinished training for epoch 8\nEpoch 8/35\n - Train Loss      : 0.8594, Train Accuracy      : 43.45%\n - Validation Loss : 1.4302, Validation Accuracy : 32.38%\n\nEpoch 9 started.\nFinished training for epoch 9\nEpoch 9/35\n - Train Loss      : 0.8022, Train Accuracy      : 48.86%\n - Validation Loss : 1.4136, Validation Accuracy : 35.88%\n\nEpoch 10 started.\nFinished training for epoch 10\nEpoch 10/35\n - Train Loss      : 0.8302, Train Accuracy      : 47.65%\n - Validation Loss : 1.4591, Validation Accuracy : 33.82%\n\nEpoch 11 started.\nFinished training for epoch 11\nEpoch 11/35\n - Train Loss      : 0.7716, Train Accuracy      : 52.94%\n - Validation Loss : 1.4729, Validation Accuracy : 36.84%\n\nEpoch 12 started.\nFinished training for epoch 12\nEpoch 12/35\n - Train Loss      : 0.8190, Train Accuracy      : 51.90%\n - Validation Loss : 1.5237, Validation Accuracy : 35.67%\n\nEpoch 13 started.\nFinished training for epoch 13\nEpoch 13/35\n - Train Loss      : 0.7341, Train Accuracy      : 58.29%\n - Validation Loss : 1.5416, Validation Accuracy : 39.74%\n\nEpoch 14 started.\nFinished training for epoch 14\nEpoch 14/35\n - Train Loss      : 0.7206, Train Accuracy      : 60.12%\n - Validation Loss : 1.5592, Validation Accuracy : 40.52%\n\nEpoch 15 started.\nFinished training for epoch 15\nEpoch 15/35\n - Train Loss      : 0.7371, Train Accuracy      : 60.20%\n - Validation Loss : 1.6129, Validation Accuracy : 39.55%\n\nEpoch 16 started.\nFinished training for epoch 16\nEpoch 16/35\n - Train Loss      : 0.7086, Train Accuracy      : 63.19%\n - Validation Loss : 1.6223, Validation Accuracy : 41.08%\n\nEpoch 17 started.\nFinished training for epoch 17\nEpoch 17/35\n - Train Loss      : 0.6963, Train Accuracy      : 65.45%\n - Validation Loss : 1.6565, Validation Accuracy : 42.08%\n\nEpoch 18 started.\nFinished training for epoch 18\nEpoch 18/35\n - Train Loss      : 0.6909, Train Accuracy      : 66.20%\n - Validation Loss : 1.6839, Validation Accuracy : 41.82%\n\nEpoch 19 started.\nFinished training for epoch 19\nEpoch 19/35\n - Train Loss      : 0.6751, Train Accuracy      : 67.78%\n - Validation Loss : 1.7169, Validation Accuracy : 42.03%\n\nEpoch 20 started.\nFinished training for epoch 20\nEpoch 20/35\n - Train Loss      : 0.6557, Train Accuracy      : 69.40%\n - Validation Loss : 1.7348, Validation Accuracy : 41.94%\n\nEpoch 21 started.\nFinished training for epoch 21\nEpoch 21/35\n - Train Loss      : 0.6355, Train Accuracy      : 70.88%\n - Validation Loss : 1.7553, Validation Accuracy : 42.72%\n\nEpoch 22 started.\nFinished training for epoch 22\nEpoch 22/35\n - Train Loss      : 0.6348, Train Accuracy      : 72.36%\n - Validation Loss : 1.7892, Validation Accuracy : 43.13%\n\nEpoch 23 started.\nFinished training for epoch 23\nEpoch 23/35\n - Train Loss      : 0.6504, Train Accuracy      : 72.56%\n - Validation Loss : 1.7888, Validation Accuracy : 43.54%\n\nEpoch 24 started.\nFinished training for epoch 24\nEpoch 24/35\n - Train Loss      : 0.6324, Train Accuracy      : 73.41%\n - Validation Loss : 1.8319, Validation Accuracy : 43.14%\n\nEpoch 25 started.\nFinished training for epoch 25\nEpoch 25/35\n - Train Loss      : 0.6076, Train Accuracy      : 74.96%\n - Validation Loss : 1.8705, Validation Accuracy : 43.16%\n\nEpoch 26 started.\nFinished training for epoch 26\nEpoch 26/35\n - Train Loss      : 0.5599, Train Accuracy      : 76.94%\n - Validation Loss : 1.8689, Validation Accuracy : 43.93%\n\nEpoch 27 started.\nFinished training for epoch 27\nEpoch 27/35\n - Train Loss      : 0.5493, Train Accuracy      : 77.55%\n - Validation Loss : 1.8851, Validation Accuracy : 44.15%\n\nEpoch 28 started.\nFinished training for epoch 28\nEpoch 28/35\n - Train Loss      : 0.5757, Train Accuracy      : 77.80%\n - Validation Loss : 1.9060, Validation Accuracy : 44.31%\n\nEpoch 29 started.\nFinished training for epoch 29\nEpoch 29/35\n - Train Loss      : 0.5626, Train Accuracy      : 78.61%\n - Validation Loss : 1.9575, Validation Accuracy : 44.16%\n\nEpoch 30 started.\nFinished training for epoch 30\nEpoch 30/35\n - Train Loss      : 0.5583, Train Accuracy      : 79.15%\n - Validation Loss : 1.9497, Validation Accuracy : 44.41%\n\nEpoch 31 started.\nFinished training for epoch 31\nEpoch 31/35\n - Train Loss      : 0.5104, Train Accuracy      : 81.51%\n - Validation Loss : 1.9771, Validation Accuracy : 45.81%\n\nEpoch 32 started.\nFinished training for epoch 32\nEpoch 32/35\n - Train Loss      : 0.4796, Train Accuracy      : 82.93%\n - Validation Loss : 1.9903, Validation Accuracy : 46.56%\n\nEpoch 33 started.\nFinished training for epoch 33\nEpoch 33/35\n - Train Loss      : 0.4569, Train Accuracy      : 84.22%\n - Validation Loss : 1.9974, Validation Accuracy : 47.02%\n\nEpoch 34 started.\nFinished training for epoch 34\nEpoch 34/35\n - Train Loss      : 0.4369, Train Accuracy      : 85.52%\n - Validation Loss : 1.9777, Validation Accuracy : 47.54%\n\nEpoch 35 started.\nFinished training for epoch 35\nEpoch 35/35\n - Train Loss      : 0.4244, Train Accuracy      : 86.33%\n - Validation Loss : 2.0098, Validation Accuracy : 47.38%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:12**"
      ],
      "metadata": {
        "id": "1w-Au6TBk1WM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = evaluate_model(final_model,test_data_loader, criterion, device)\n",
        "print(f' Test Accuracy: {test_accuracy:.2f}')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T11:28:54.715061Z",
          "iopub.execute_input": "2025-05-18T11:28:54.715357Z",
          "iopub.status.idle": "2025-05-18T11:28:58.005419Z",
          "shell.execute_reply.started": "2025-05-18T11:28:54.715339Z",
          "shell.execute_reply": "2025-05-18T11:28:58.004645Z"
        },
        "id": "Brv2qRS2LRUT",
        "outputId": "c0527d3e-4036-4f12-a1e2-350cb80de867"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": " Test Accuracy: 46.74\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:13**"
      ],
      "metadata": {
        "id": "5TlZAjaFk6go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(model, dataloader, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actual = []\n",
        "    with torch.no_grad():\n",
        "        for latin, devanagari in dataloader:\n",
        "            latin = latin.to(device)\n",
        "            devanagari = devanagari.to(device)\n",
        "            output, _ = model(latin, devanagari, 0)\n",
        "            deb = devanagari.cpu().numpy()\n",
        "            actual.append(deb)\n",
        "            if output.dim() == 3:\n",
        "                output = output.argmax(2)\n",
        "            elif output.dim() == 2:\n",
        "                output = output.argmax(1)\n",
        "            else:\n",
        "                print(\"Unexpected output dimension:\", output.dim())\n",
        "                continue\n",
        "\n",
        "            latin = latin.cpu().numpy()\n",
        "            output = output.cpu().numpy()\n",
        "            predictions.append((latin, output))\n",
        "    return predictions, actual\n",
        "latin_idx2token = {idx: char for char, idx in test_input_letter_vocab.items()}\n",
        "bangla_idx2token = {idx: char for char, idx in test_target_letter_vocab.items()}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T11:29:07.365833Z",
          "iopub.execute_input": "2025-05-18T11:29:07.366103Z",
          "iopub.status.idle": "2025-05-18T11:29:07.372247Z",
          "shell.execute_reply.started": "2025-05-18T11:29:07.366083Z",
          "shell.execute_reply": "2025-05-18T11:29:07.371662Z"
        },
        "id": "21q9HZyDLRUT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:14**"
      ],
      "metadata": {
        "id": "C5KO_AnGk-C8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(indices, idx2token, target_vocab):\n",
        "    valid_indices = []\n",
        "    for idx in indices:\n",
        "        if idx in idx2token and idx not in (target_vocab['<pad>'], target_vocab['<sos>'], target_vocab['<eos>']):\n",
        "            valid_indices.append(idx)\n",
        "    decoded_text = ''\n",
        "    for idx in valid_indices:\n",
        "        decoded_text += idx2token[idx]\n",
        "    return decoded_text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T11:29:10.414540Z",
          "iopub.execute_input": "2025-05-18T11:29:10.415271Z",
          "iopub.status.idle": "2025-05-18T11:29:10.419783Z",
          "shell.execute_reply.started": "2025-05-18T11:29:10.415244Z",
          "shell.execute_reply": "2025-05-18T11:29:10.419026Z"
        },
        "id": "2Xy4iEaSLRUT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:15**"
      ],
      "metadata": {
        "id": "tjhivsTrlB8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_output_indices(indices, idx2token, target_vocab):\n",
        "    decoded_text = ''\n",
        "    for idx in indices:\n",
        "        if idx == target_vocab.get('<eos>'):\n",
        "            break\n",
        "        if idx in (target_vocab.get('<pad>'), target_vocab.get('<sos>')):\n",
        "            continue\n",
        "        decoded_text += idx2token.get(idx, '')\n",
        "    return decoded_text"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T11:29:12.215489Z",
          "iopub.execute_input": "2025-05-18T11:29:12.215755Z",
          "iopub.status.idle": "2025-05-18T11:29:12.220029Z",
          "shell.execute_reply.started": "2025-05-18T11:29:12.215738Z",
          "shell.execute_reply": "2025-05-18T11:29:12.219342Z"
        },
        "id": "j9bwu952LRUT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step:16**"
      ],
      "metadata": {
        "id": "hF5TDJjNlGTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "test_predictions, actual = run_inference(final_model, test_data_loader, device)\n",
        "seq2seq_results = []\n",
        "for (src_indices, output_indices), act_ind in zip(test_predictions, actual):\n",
        "    for i in range(src_indices.shape[0]):\n",
        "        input_text = decode_sequence(src_indices[i], latin_idx2token, test_input_letter_vocab)\n",
        "        actual_target_text = decode_sequence(act_ind[i], bangla_idx2token, test_target_letter_vocab)\n",
        "        predicted_text = process_output_indices(output_indices[i], bangla_idx2token, test_target_letter_vocab)\n",
        "        seq2seq_results.append([input_text, actual_target_text, predicted_text])\n",
        "results_df = pd.DataFrame(seq2seq_results, columns=[\"Input\", \"Actual\", \"Predicted\"])\n",
        "def char_level_accuracy(actual, predicted):\n",
        "    matches = sum(a == b for a, b in zip(actual, predicted))\n",
        "    return matches / max(len(actual), len(predicted)) if max(len(actual), len(predicted)) > 0 else 0\n",
        "\n",
        "results_df[\"Accuracy\"] = results_df.apply(lambda row: char_level_accuracy(row[\"Actual\"], row[\"Predicted\"]), axis=1)\n",
        "total = len(results_df)\n",
        "count_100 = (results_df[\"Accuracy\"] == 1.0).sum()\n",
        "count_75 = ((results_df[\"Accuracy\"] > 0.75) & (results_df[\"Accuracy\"] < 1.0)).sum()\n",
        "count_50 = ((results_df[\"Accuracy\"] > 0.5) & (results_df[\"Accuracy\"] <= 0.75)).sum()\n",
        "count_25 = ((results_df[\"Accuracy\"] > 0.25) & (results_df[\"Accuracy\"] <= 0.5)).sum()\n",
        "count_0 = (results_df[\"Accuracy\"] <= 0.25).sum()\n",
        "def accuracy_highlighter(row):\n",
        "    acc = row.Accuracy\n",
        "    if acc == 1.0:\n",
        "        color = 'background-color: #d4edda'  # Green\n",
        "    elif acc > 0.75:\n",
        "        color = 'background-color: #cce5ff'  # Light blue\n",
        "    elif acc > 0.5:\n",
        "        color = 'background-color: #fff3cd'  # Light yellow\n",
        "    elif acc > 0.25:\n",
        "        color = 'background-color: #f8d7da'  # Light pink\n",
        "    else:\n",
        "        color = ''\n",
        "    return [color, color, color, '']\n",
        "styled_table = results_df.style.set_properties(**{\n",
        "    'border': '1px solid black',\n",
        "    'text-align': 'left',\n",
        "    'padding': '6px'\n",
        "}).apply(accuracy_highlighter, axis=1).hide(axis=\"columns\", subset=[\"Accuracy\"])\n",
        "\n",
        "html_content = styled_table.to_html()\n",
        "summary_html = f\"\"\"\n",
        "<div class=\"legend\">\n",
        "    <h3>Prediction Accuracy Summary</h3>\n",
        "    <ul>\n",
        "        <li><strong>Total Predictions:</strong> {total}</li>\n",
        "        <li style=\"background-color: #d4edda; padding: 6px;\">✅ 100% Match: {count_100}</li>\n",
        "        <li style=\"background-color: #cce5ff; padding: 6px;\">✅ Above 75%: {count_75}</li>\n",
        "        <li style=\"background-color: #fff3cd; padding: 6px;\">✅ Above 50%: {count_50}</li>\n",
        "        <li style=\"background-color: #f8d7da; padding: 6px;\">✅ Above 25%: {count_25}</li>\n",
        "        <li>❌ ≤ 25% Match: {count_0}</li>\n",
        "    </ul>\n",
        "</div>\n",
        "\"\"\"\n",
        "html_full = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <title>Seq2Seq Prediction Results</title>\n",
        "    <style>\n",
        "        body {{\n",
        "            font-family: Arial, sans-serif;\n",
        "            background-color: #f5f5f5;\n",
        "            padding: 30px;\n",
        "        }}\n",
        "        h2 {{\n",
        "            text-align: center;\n",
        "            color: #333;\n",
        "        }}\n",
        "        .legend {{\n",
        "            max-width: 600px;\n",
        "            margin: 0 auto 30px auto;\n",
        "            padding: 15px;\n",
        "            border: 1px solid #ccc;\n",
        "            background-color: #fff;\n",
        "        }}\n",
        "        .legend h3 {{\n",
        "            margin-top: 0;\n",
        "        }}\n",
        "        table {{\n",
        "            margin: auto;\n",
        "            border-collapse: collapse;\n",
        "            box-shadow: 0 0 10px rgba(0,0,0,0.1);\n",
        "        }}\n",
        "        th {{\n",
        "            background-color: #4CAF50;\n",
        "            color: white;\n",
        "        }}\n",
        "        td, th {{\n",
        "            padding: 10px 15px;\n",
        "            border: 1px solid #ddd;\n",
        "        }}\n",
        "        tr:nth-child(even) {{\n",
        "            background-color: #f9f9f9;\n",
        "        }}\n",
        "        tr:hover {{\n",
        "            background-color: #f1f1f1;\n",
        "        }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h2>Character-Level Transliteration Predictions using Seq2Seq(without attention)</h2>\n",
        "    {summary_html}\n",
        "    {html_content}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "with open(\" predictions_vanilla.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html_full)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-18T11:30:57.970660Z",
          "iopub.execute_input": "2025-05-18T11:30:57.971294Z",
          "iopub.status.idle": "2025-05-18T11:31:03.144699Z",
          "shell.execute_reply.started": "2025-05-18T11:30:57.971255Z",
          "shell.execute_reply": "2025-05-18T11:31:03.143867Z"
        },
        "id": "dfN-9jmGLRUT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "OUysNkEtLRUT"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}